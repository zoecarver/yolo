{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-22T02:58:22.752545Z",
     "start_time": "2018-12-22T02:58:22.748350Z"
    }
   },
   "outputs": [],
   "source": [
    "input_python = \"\"\"\n",
    "# Layer 1\n",
    "x = Conv2D(32, (3,3), strides=(1,1), padding='same', name='conv_1', use_bias=False)(input_image)\n",
    "x = BatchNormalization(name='norm_1')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "# Layer 2\n",
    "x = Conv2D(64, (3,3), strides=(1,1), padding='same', name='conv_2', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_2')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "# Layer 3\n",
    "x = Conv2D(128, (3,3), strides=(1,1), padding='same', name='conv_3', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_3')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 4\n",
    "x = Conv2D(64, (1,1), strides=(1,1), padding='same', name='conv_4', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_4')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 5\n",
    "x = Conv2D(128, (3,3), strides=(1,1), padding='same', name='conv_5', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_5')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "# Layer 6\n",
    "x = Conv2D(256, (3,3), strides=(1,1), padding='same', name='conv_6', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_6')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 7\n",
    "x = Conv2D(128, (1,1), strides=(1,1), padding='same', name='conv_7', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_7')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 8\n",
    "x = Conv2D(256, (3,3), strides=(1,1), padding='same', name='conv_8', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_8')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "# Layer 9\n",
    "x = Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_9', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_9')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 10\n",
    "x = Conv2D(256, (1,1), strides=(1,1), padding='same', name='conv_10', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_10')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 11\n",
    "x = Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_11', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_11')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 12\n",
    "x = Conv2D(256, (1,1), strides=(1,1), padding='same', name='conv_12', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_12')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 13\n",
    "x = Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_13', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_13')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "skip_connection = x\n",
    "\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "# Layer 14\n",
    "x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_14', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_14')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 15\n",
    "x = Conv2D(512, (1,1), strides=(1,1), padding='same', name='conv_15', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_15')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 16\n",
    "x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_16', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_16')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 17\n",
    "x = Conv2D(512, (1,1), strides=(1,1), padding='same', name='conv_17', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_17')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 18\n",
    "x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_18', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_18')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 19\n",
    "x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_19', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_19')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 20\n",
    "x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_20', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_20')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 21\n",
    "skip_connection = Conv2D(64, (1,1), strides=(1,1), padding='same', name='conv_21', use_bias=False)(skip_connection)\n",
    "skip_connection = BatchNormalization(name='norm_21')(skip_connection)\n",
    "skip_connection = LeakyReLU(alpha=0.1)(skip_connection)\n",
    "skip_connection = Lambda(space_to_depth_x2)(skip_connection)\n",
    "\n",
    "x = concatenate([skip_connection, x])\n",
    "\n",
    "# Layer 22\n",
    "x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_22', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_22')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-22T03:06:09.859092Z",
     "start_time": "2018-12-22T03:06:09.850190Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_name(function):\n",
    "    if function == 'Conv2D':\n",
    "        return 'convolutional'\n",
    "    if function == 'Input':\n",
    "        return 'input'\n",
    "    if function == 'MaxPooling2D':\n",
    "        return 'maxpooling'\n",
    "    if function == 'Lambda':\n",
    "        return 'custom'\n",
    "    return None\n",
    "\n",
    "\n",
    "def parse_line(line):\n",
    "    try:\n",
    "        function = line.split(' ')[2].split('(')[0]\n",
    "        name = get_name(function)\n",
    "    except:\n",
    "        return\n",
    "    \n",
    "    if name == 'convolutional':\n",
    "        filters = line.split(' ')[2].split('(')[1].split(',')[0]\n",
    "        kernel = line.split(' ')[3].split(',')[0].split('(')[1]\n",
    "        strides = line.split(' ')[4].split(',')[0].split('=(')[1]\n",
    "    \n",
    "        return {\n",
    "            'name': name,\n",
    "            'filters': filters,\n",
    "            'kernel': kernel,\n",
    "            'strides': strides,\n",
    "        }\n",
    "    \n",
    "    if name == 'maxpooling':\n",
    "        pool = line.split(' ')[2].split('(')[2].split(',')[0]\n",
    "        \n",
    "        return {\n",
    "            'name': name,\n",
    "            'pool': pool\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-22T03:06:10.050526Z",
     "start_time": "2018-12-22T03:06:10.042267Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'convolutional', 'filters': '32', 'kernel': '3', 'strides': '1'},\n",
       " {'name': 'maxpooling', 'pool': '2'},\n",
       " {'name': 'convolutional', 'filters': '64', 'kernel': '3', 'strides': '1'},\n",
       " {'name': 'maxpooling', 'pool': '2'},\n",
       " {'name': 'convolutional', 'filters': '128', 'kernel': '3', 'strides': '1'},\n",
       " {'name': 'convolutional', 'filters': '64', 'kernel': '1', 'strides': '1'},\n",
       " {'name': 'convolutional', 'filters': '128', 'kernel': '3', 'strides': '1'},\n",
       " {'name': 'maxpooling', 'pool': '2'},\n",
       " {'name': 'convolutional', 'filters': '256', 'kernel': '3', 'strides': '1'},\n",
       " {'name': 'convolutional', 'filters': '128', 'kernel': '1', 'strides': '1'},\n",
       " {'name': 'convolutional', 'filters': '256', 'kernel': '3', 'strides': '1'},\n",
       " {'name': 'maxpooling', 'pool': '2'},\n",
       " {'name': 'convolutional', 'filters': '512', 'kernel': '3', 'strides': '1'},\n",
       " {'name': 'convolutional', 'filters': '256', 'kernel': '1', 'strides': '1'},\n",
       " {'name': 'convolutional', 'filters': '512', 'kernel': '3', 'strides': '1'},\n",
       " {'name': 'convolutional', 'filters': '256', 'kernel': '1', 'strides': '1'},\n",
       " {'name': 'convolutional', 'filters': '512', 'kernel': '3', 'strides': '1'},\n",
       " {'name': 'maxpooling', 'pool': '2'},\n",
       " {'name': 'convolutional', 'filters': '1024', 'kernel': '3', 'strides': '1'},\n",
       " {'name': 'convolutional', 'filters': '512', 'kernel': '1', 'strides': '1'},\n",
       " {'name': 'convolutional', 'filters': '1024', 'kernel': '3', 'strides': '1'},\n",
       " {'name': 'convolutional', 'filters': '512', 'kernel': '1', 'strides': '1'},\n",
       " {'name': 'convolutional', 'filters': '1024', 'kernel': '3', 'strides': '1'},\n",
       " {'name': 'convolutional', 'filters': '1024', 'kernel': '3', 'strides': '1'},\n",
       " {'name': 'convolutional', 'filters': '1024', 'kernel': '3', 'strides': '1'},\n",
       " {'name': 'convolutional', 'filters': '64', 'kernel': '1', 'strides': '1'},\n",
       " {'name': 'convolutional', 'filters': '1024', 'kernel': '3', 'strides': '1'}]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blocks = []\n",
    "\n",
    "for line in input_python.split('\\n'):\n",
    "    block = parse_line(line)\n",
    "    if block is not None:\n",
    "        blocks += [block]\n",
    "    \n",
    "blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-22T03:06:10.432031Z",
     "start_time": "2018-12-22T03:06:10.424570Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n[convolutional]\\nfilters=32\\nkernel=3\\nstrides=1\\n\\n[maxpooling]\\npool=2\\n\\n[convolutional]\\nfilters=64\\nkernel=3\\nstrides=1\\n\\n[maxpooling]\\npool=2\\n\\n[convolutional]\\nfilters=128\\nkernel=3\\nstrides=1\\n\\n[convolutional]\\nfilters=64\\nkernel=1\\nstrides=1\\n\\n[convolutional]\\nfilters=128\\nkernel=3\\nstrides=1\\n\\n[maxpooling]\\npool=2\\n\\n[convolutional]\\nfilters=256\\nkernel=3\\nstrides=1\\n\\n[convolutional]\\nfilters=128\\nkernel=1\\nstrides=1\\n\\n[convolutional]\\nfilters=256\\nkernel=3\\nstrides=1\\n\\n[maxpooling]\\npool=2\\n\\n[convolutional]\\nfilters=512\\nkernel=3\\nstrides=1\\n\\n[convolutional]\\nfilters=256\\nkernel=1\\nstrides=1\\n\\n[convolutional]\\nfilters=512\\nkernel=3\\nstrides=1\\n\\n[convolutional]\\nfilters=256\\nkernel=1\\nstrides=1\\n\\n[convolutional]\\nfilters=512\\nkernel=3\\nstrides=1\\n\\n[maxpooling]\\npool=2\\n\\n[convolutional]\\nfilters=1024\\nkernel=3\\nstrides=1\\n\\n[convolutional]\\nfilters=512\\nkernel=1\\nstrides=1\\n\\n[convolutional]\\nfilters=1024\\nkernel=3\\nstrides=1\\n\\n[convolutional]\\nfilters=512\\nkernel=1\\nstrides=1\\n\\n[convolutional]\\nfilters=1024\\nkernel=3\\nstrides=1\\n\\n[convolutional]\\nfilters=1024\\nkernel=3\\nstrides=1\\n\\n[convolutional]\\nfilters=1024\\nkernel=3\\nstrides=1\\n\\n[convolutional]\\nfilters=64\\nkernel=1\\nstrides=1\\n\\n[convolutional]\\nfilters=1024\\nkernel=3\\nstrides=1'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_str = ''\n",
    "\n",
    "for block in blocks:\n",
    "    config_str += '\\n\\n'\n",
    "    config_str += '[%s]' % block['name']\n",
    "    del block['name']\n",
    "    \n",
    "    for key, value in block.items():\n",
    "        config_str += '\\n'\n",
    "        config_str += '%s=%s' % (key, value)\n",
    "\n",
    "config_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-22T03:06:10.968071Z",
     "start_time": "2018-12-22T03:06:10.964184Z"
    }
   },
   "outputs": [],
   "source": [
    "print(config_str, file=open('custom_yolo.cfg', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
