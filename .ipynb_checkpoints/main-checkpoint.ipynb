{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-22T03:31:38.817573Z",
     "start_time": "2018-12-22T03:31:38.812872Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, LeakyReLU, UpSampling2D, InputLayer, Concatenate, Input, merge, concatenate, Lambda, Reshape, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import plot_model\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing the config\n",
    "\n",
    "The network config is in `yolov3.cfg`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-22T03:45:03.230583Z",
     "start_time": "2018-12-22T03:45:03.222071Z"
    }
   },
   "outputs": [],
   "source": [
    "def parse_config(cfg_path, verbose=False):\n",
    "    file = open(cfg_path, 'r')\n",
    "    lines = file.readlines()\n",
    "        \n",
    "    # get rid of comments and blank lines and white space\n",
    "    lines = [x for x in lines if len(x) > 1]\n",
    "    lines = [x for x in lines if x[0] != '#']\n",
    "    lines = [x.rstrip().lstrip() for x in lines]\n",
    "\n",
    "    block = {}\n",
    "    blocks = []\n",
    "    \n",
    "    for line in lines:\n",
    "        if verbose: print('valuating line: %s' % line)\n",
    "        \n",
    "        if line[0] == '[': # new block start\n",
    "            if len(block) != 0: # if the block inst empty (has data) then reset it\n",
    "                blocks.append(block)\n",
    "                block = {}\n",
    "                \n",
    "            block['type'] = line[1:-1]\n",
    "        else:\n",
    "            key, value = line.split('=')\n",
    "            key, value = key.rstrip(), value.lstrip()\n",
    "            block[key] = value\n",
    "\n",
    "    blocks += [block]\n",
    "    return blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-22T03:45:32.733760Z",
     "start_time": "2018-12-22T03:45:32.720405Z"
    }
   },
   "outputs": [],
   "source": [
    "blocks = parse_config('custom_yolo.cfg')\n",
    "\n",
    "# configs from https://github.com/experiencor/keras-yolo2/blob/master/Yolo%20Step-by-Step.ipynb\n",
    "LABELS = ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n",
    "\n",
    "IMAGE_H, IMAGE_W = 416, 416\n",
    "GRID_H,  GRID_W  = 13 , 13\n",
    "BOX              = 5\n",
    "CLASS            = len(LABELS)\n",
    "CLASS_WEIGHTS    = np.ones(CLASS, dtype='float32')\n",
    "OBJ_THRESHOLD    = 0.3#0.5\n",
    "NMS_THRESHOLD    = 0.3#0.45\n",
    "ANCHORS          = [0.57273, 0.677385, 1.87446, 2.06253, 3.33843, 5.47434, 7.88282, 3.52778, 9.77052, 9.16828]\n",
    "\n",
    "NO_OBJECT_SCALE  = 1.0\n",
    "OBJECT_SCALE     = 5.0\n",
    "COORD_SCALE      = 1.0\n",
    "CLASS_SCALE      = 1.0\n",
    "\n",
    "BATCH_SIZE       = 16\n",
    "WARM_UP_BATCHES  = 0\n",
    "TRUE_BOX_BUFFER  = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix shortcut issue\n",
    "this is a quick fix for the shortcut issue I was running into but I want to figure out why and how this works so I can create a better implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-22T03:45:33.971827Z",
     "start_time": "2018-12-22T03:45:33.968248Z"
    }
   },
   "outputs": [],
   "source": [
    "def space_to_depth_x2(x):\n",
    "    return tf.space_to_depth(x, block_size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The model\n",
    "\n",
    "(add specific info about the model)\n",
    "\n",
    "### Questions:\n",
    "1. Why is padding important in a convolutional layer\n",
    "2. What is `BatchNormalization` and why is it important\n",
    "3. What does `bilinear` mean?\n",
    "4. What is `B X C X H X W` and how is it difforent than other formats\n",
    "5. What is the difforence between route and shortcut and how are they implemented?\n",
    "    * see the degradation problem, and an [explaination here](https://www.quora.com/What-are-shortcut-connections-how-do-they-work-and-what-is-their-role-in-the-paper-Deep-Residual-Learning-for-Image-Recognition).\n",
    "6. What does `space_to_depth_x2` do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-22T03:45:42.191162Z",
     "start_time": "2018-12-22T03:45:35.048674Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0/31) processing: convolutional\n",
      "(1/31) processing: maxpooling\n",
      "(2/31) processing: convolutional\n",
      "(3/31) processing: maxpooling\n",
      "(4/31) processing: convolutional\n",
      "(5/31) processing: convolutional\n",
      "(6/31) processing: convolutional\n",
      "(7/31) processing: maxpooling\n",
      "(8/31) processing: convolutional\n",
      "(9/31) processing: convolutional\n",
      "(10/31) processing: convolutional\n",
      "(11/31) processing: maxpooling\n",
      "(12/31) processing: convolutional\n",
      "(13/31) processing: convolutional\n",
      "(14/31) processing: convolutional\n",
      "(15/31) processing: convolutional\n",
      "(16/31) processing: convolutional\n",
      "(17/31) processing: skip_connection\n",
      "(18/31) processing: maxpooling\n",
      "(19/31) processing: convolutional\n",
      "(20/31) processing: convolutional\n",
      "(21/31) processing: convolutional\n",
      "(22/31) processing: convolutional\n",
      "(23/31) processing: convolutional\n",
      "(24/31) processing: convolutional\n",
      "(25/31) processing: convolutional\n",
      "(26/31) processing: skip_connection\n",
      "(27/31) processing: convolutional\n",
      "(28/31) processing: space_to_depth\n",
      "(29/31) processing: concatenate\n",
      "(30/31) processing: convolutional\n",
      "(31/31) processing: net\n"
     ]
    }
   ],
   "source": [
    "input_layer = blocks[0]\n",
    "input_shape = (int(input_layer['shape']), \n",
    "    int(input_layer['shape']), \n",
    "    int(input_layer['channels']))\n",
    "\n",
    "model_input = Input(input_shape)\n",
    "x = model_input\n",
    "\n",
    "skip_connection = None\n",
    "skip_connection_x = None\n",
    "output = None\n",
    "model = None\n",
    "\n",
    "for index, block in enumerate(blocks[1:]):\n",
    "    print('(%i/%i) processing: %s' % (index, len(blocks) - 2, block['type']))\n",
    "    \n",
    "    if block['type'] == 'convolutional':\n",
    "        filters = int(block['filters'])\n",
    "        kernel = int(block['kernel'])\n",
    "        strides = int(block['strides'])\n",
    "        \n",
    "        x = Conv2D(filters, \n",
    "                   (kernel, kernel), \n",
    "                   strides=(strides, strides), \n",
    "                   padding='same', \n",
    "                   name='conv_%i' % index,\n",
    "                   use_bias=False)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = LeakyReLU(alpha=0.1)(x)\n",
    "        \n",
    "    if block['type'] == 'maxpooling':\n",
    "        pool = int(block['pool'])\n",
    "        \n",
    "        x = MaxPooling2D(pool_size=(pool, pool))(x)\n",
    "        \n",
    "    if block['type'] == 'skip_connection':\n",
    "        open_connection = int(block['open'])\n",
    "        \n",
    "        if open_connection:\n",
    "            skip_connection = x # hold current x for later\n",
    "        else:\n",
    "            skip_connection_x = x # make sure we know what this is for concat\n",
    "            x = skip_connection # set x to skip connect from earlier\n",
    "    \n",
    "    if block['type'] == 'space_to_depth':\n",
    "        x = Lambda(space_to_depth_x2)(x)\n",
    "        \n",
    "    if block['type'] == 'concatenate':\n",
    "        x = concatenate([x, skip_connection_x])\n",
    "        \n",
    "    if block['type'] == 'net':\n",
    "        x = Conv2D(\n",
    "            BOX * (4 + 1 + CLASS), (1, 1), strides=(1, 1), padding='same')(x)\n",
    "        output = Reshape((GRID_H, GRID_W, BOX, 4 + 1 + CLASS))(x)\n",
    "#         output = Lambda(lambda a: a[0])([output])\n",
    "        \n",
    "        model = Model(model_input, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-22T03:46:02.559793Z",
     "start_time": "2018-12-22T03:45:59.925829Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_29 (InputLayer)           (None, 416, 416, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_0 (Conv2D)                 (None, 416, 416, 32) 864         input_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_755 (BatchN (None, 416, 416, 32) 128         conv_0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_755 (LeakyReLU)     (None, 416, 416, 32) 0           batch_normalization_755[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_64 (MaxPooling2D) (None, 208, 208, 32) 0           leaky_re_lu_755[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv_2 (Conv2D)                 (None, 208, 208, 64) 18432       max_pooling2d_64[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_756 (BatchN (None, 208, 208, 64) 256         conv_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_756 (LeakyReLU)     (None, 208, 208, 64) 0           batch_normalization_756[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_65 (MaxPooling2D) (None, 104, 104, 64) 0           leaky_re_lu_756[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv_4 (Conv2D)                 (None, 104, 104, 128 73728       max_pooling2d_65[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_757 (BatchN (None, 104, 104, 128 512         conv_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_757 (LeakyReLU)     (None, 104, 104, 128 0           batch_normalization_757[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv_5 (Conv2D)                 (None, 104, 104, 64) 8192        leaky_re_lu_757[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_758 (BatchN (None, 104, 104, 64) 256         conv_5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_758 (LeakyReLU)     (None, 104, 104, 64) 0           batch_normalization_758[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv_6 (Conv2D)                 (None, 104, 104, 128 73728       leaky_re_lu_758[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_759 (BatchN (None, 104, 104, 128 512         conv_6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_759 (LeakyReLU)     (None, 104, 104, 128 0           batch_normalization_759[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_66 (MaxPooling2D) (None, 52, 52, 128)  0           leaky_re_lu_759[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv_8 (Conv2D)                 (None, 52, 52, 256)  294912      max_pooling2d_66[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_760 (BatchN (None, 52, 52, 256)  1024        conv_8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_760 (LeakyReLU)     (None, 52, 52, 256)  0           batch_normalization_760[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv_9 (Conv2D)                 (None, 52, 52, 128)  32768       leaky_re_lu_760[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_761 (BatchN (None, 52, 52, 128)  512         conv_9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_761 (LeakyReLU)     (None, 52, 52, 128)  0           batch_normalization_761[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv_10 (Conv2D)                (None, 52, 52, 256)  294912      leaky_re_lu_761[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_762 (BatchN (None, 52, 52, 256)  1024        conv_10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_762 (LeakyReLU)     (None, 52, 52, 256)  0           batch_normalization_762[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_67 (MaxPooling2D) (None, 26, 26, 256)  0           leaky_re_lu_762[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv_12 (Conv2D)                (None, 26, 26, 512)  1179648     max_pooling2d_67[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_763 (BatchN (None, 26, 26, 512)  2048        conv_12[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_763 (LeakyReLU)     (None, 26, 26, 512)  0           batch_normalization_763[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv_13 (Conv2D)                (None, 26, 26, 256)  131072      leaky_re_lu_763[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_764 (BatchN (None, 26, 26, 256)  1024        conv_13[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_764 (LeakyReLU)     (None, 26, 26, 256)  0           batch_normalization_764[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv_14 (Conv2D)                (None, 26, 26, 512)  1179648     leaky_re_lu_764[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_765 (BatchN (None, 26, 26, 512)  2048        conv_14[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_765 (LeakyReLU)     (None, 26, 26, 512)  0           batch_normalization_765[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv_15 (Conv2D)                (None, 26, 26, 256)  131072      leaky_re_lu_765[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_766 (BatchN (None, 26, 26, 256)  1024        conv_15[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_766 (LeakyReLU)     (None, 26, 26, 256)  0           batch_normalization_766[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv_16 (Conv2D)                (None, 26, 26, 512)  1179648     leaky_re_lu_766[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_767 (BatchN (None, 26, 26, 512)  2048        conv_16[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_767 (LeakyReLU)     (None, 26, 26, 512)  0           batch_normalization_767[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_68 (MaxPooling2D) (None, 13, 13, 512)  0           leaky_re_lu_767[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv_19 (Conv2D)                (None, 13, 13, 1024) 4718592     max_pooling2d_68[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_768 (BatchN (None, 13, 13, 1024) 4096        conv_19[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_768 (LeakyReLU)     (None, 13, 13, 1024) 0           batch_normalization_768[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv_20 (Conv2D)                (None, 13, 13, 512)  524288      leaky_re_lu_768[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_769 (BatchN (None, 13, 13, 512)  2048        conv_20[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_769 (LeakyReLU)     (None, 13, 13, 512)  0           batch_normalization_769[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv_21 (Conv2D)                (None, 13, 13, 1024) 4718592     leaky_re_lu_769[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_770 (BatchN (None, 13, 13, 1024) 4096        conv_21[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_770 (LeakyReLU)     (None, 13, 13, 1024) 0           batch_normalization_770[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv_22 (Conv2D)                (None, 13, 13, 512)  524288      leaky_re_lu_770[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_771 (BatchN (None, 13, 13, 512)  2048        conv_22[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_771 (LeakyReLU)     (None, 13, 13, 512)  0           batch_normalization_771[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv_23 (Conv2D)                (None, 13, 13, 1024) 4718592     leaky_re_lu_771[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_772 (BatchN (None, 13, 13, 1024) 4096        conv_23[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_772 (LeakyReLU)     (None, 13, 13, 1024) 0           batch_normalization_772[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv_24 (Conv2D)                (None, 13, 13, 1024) 9437184     leaky_re_lu_772[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_773 (BatchN (None, 13, 13, 1024) 4096        conv_24[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_27 (Conv2D)                (None, 26, 26, 64)   32768       leaky_re_lu_767[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_773 (LeakyReLU)     (None, 13, 13, 1024) 0           batch_normalization_773[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_775 (BatchN (None, 26, 26, 64)   256         conv_27[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_25 (Conv2D)                (None, 13, 13, 1024) 9437184     leaky_re_lu_773[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_775 (LeakyReLU)     (None, 26, 26, 64)   0           batch_normalization_775[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_774 (BatchN (None, 13, 13, 1024) 4096        conv_25[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 13, 13, 256)  0           leaky_re_lu_775[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_774 (LeakyReLU)     (None, 13, 13, 1024) 0           batch_normalization_774[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 13, 13, 1280) 0           lambda_8[0][0]                   \n",
      "                                                                 leaky_re_lu_774[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv_30 (Conv2D)                (None, 13, 13, 1024) 11796480    concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_776 (BatchN (None, 13, 13, 1024) 4096        conv_30[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_776 (LeakyReLU)     (None, 13, 13, 1024) 0           batch_normalization_776[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_733 (Conv2D)             (None, 13, 13, 425)  435625      leaky_re_lu_776[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 13, 13, 5, 85 0           conv2d_733[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 50,983,561\n",
      "Trainable params: 50,962,889\n",
      "Non-trainable params: 20,672\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions\n",
    "Output and generating predictions\n",
    "\n",
    "### Output Tensor\n",
    "![image](https://cdn-images-1.medium.com/max/1600/1*cGfWw6lGmV1xUKRsd--JxQ.png)\n",
    "\n",
    "Each coordinate is represented like this:\n",
    "![image.png](https://blog.paperspace.com/content/images/2018/04/bbox_-2.png)\n",
    "the coordinates are the x, y in the matrix of anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-21T06:21:27.747392Z",
     "start_time": "2018-12-21T06:21:27.653171Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(416, 416, 3)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "img = cv2.imread(\"dog-cycle-car.png\")\n",
    "img = cv2.resize(img, (416, 416)) # resize to the input dimension\n",
    "img_ =  img[:, :, ::-1].transpose((2, 0, 1))  # BGR -> RGB | H X W C -> C X H X W \n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-21T06:21:30.988553Z",
     "start_time": "2018-12-21T06:21:28.086633Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 14, 14, 255)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_prediction = main_modle.predict(np.array([img]))\n",
    "test_prediction.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T18:53:18.733929Z",
     "start_time": "2018-12-20T18:53:18.729557Z"
    }
   },
   "source": [
    "The above output will need to be changed into a an array like the one in the image above\n",
    "\n",
    "### Questions\n",
    "1. what is the 3rd attribute\n",
    "2. could you use another network to decrease grid size?\n",
    "3. what is this doing? `tf.math.exp(prediction[:, :, 2:4]) * anchors`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-21T06:26:40.939334Z",
     "start_time": "2018-12-21T06:26:40.920246Z"
    }
   },
   "outputs": [],
   "source": [
    "def format_prediction(prediction, network_info):\n",
    "    \"\"\"\n",
    "    :param network_info: first block\n",
    "    \"\"\"\n",
    "#     from IPython.core.debugger import Tracer; Tracer()()\n",
    "    \n",
    "    anchors = [(10,13),  (16,30),  (33,23),  (30,61),  (62,45),  (59,119),  (116,90),  (156,198),  (373,326)]\n",
    "    \n",
    "    network_height = int(network_info['height'])\n",
    "    network_class_count = int(network_info['classes'])\n",
    "    \n",
    "    shape = prediction.shape\n",
    "    batch_size = shape[0]\n",
    "    stride = network_height // shape[2] # strides to map output position to real position\n",
    "    grid_size = network_height // stride\n",
    "    box_attributes = 5 + network_class_count # each box starts out with 5 attributes (xmin, xmax, ymin, ymax, ?)\n",
    "    anchor_count = len(anchors) # TODO: get anchors from yolo layer\n",
    "    \n",
    "    prediction = prediction.reshape((\n",
    "        batch_size, box_attributes * anchor_count, grid_size * grid_size))\n",
    "    prediction = tf.transpose(tf.reshape(prediction, [1, 2]))\n",
    "    prediction = prediction.reshape((\n",
    "        batch_size, grid_size * grid_size * num_anchors, box_attributes))\n",
    "    \n",
    "    anchors = [(a[0] / stride, a[1] / stride) for a in anchors] # update anchors for strides\n",
    "    prediction[:, :, 0] = tf.math.sigmoid(prediction[:, :, 0]) # apply sigmoid to x, y and confidence\n",
    "    prediction[:, :, 1] = tf.math.sigmoid(prediction[:, :, 1])\n",
    "    prediction[:, :, 4] = tf.math.sigmoid(prediction[:, :, 4])\n",
    "    \n",
    "    grid = np.arange(grid_size)\n",
    "    a, b = np.meshgrid(grid, grid)\n",
    "    \n",
    "    x_offset = a.reshape((-1, 1))\n",
    "    y_offset = b.reshape((-1, 1))\n",
    "    \n",
    "    x_y_offset = np.concatenate((x_offset, y_offset), axis=1).repeat(1, num_anchors).reshape((1, -1, 2))\n",
    "    \n",
    "    prediction[:, :, :2] += x_y_offset\n",
    "\n",
    "    anchors = anchors.repeat(grid_size * grid_size, 1)\n",
    "    anchors = anchors.reshape((1,) + anchors.shape)\n",
    "    \n",
    "    prediction[:, :, 2:4] = tf.math.exp(prediction[:, :, 2:4]) * anchors\n",
    "    # apply sigmoid activation to all the classes\n",
    "    prediction[:, :, 5:5 + num_classes] = tf.math.sigmoid((prediction[:, :, 5:5 + num_classes]))\n",
    "\n",
    "    prediction[:, :, :4] *= stride # to make it reasonable for boxes\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-21T06:26:42.897626Z",
     "start_time": "2018-12-21T06:26:41.924108Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 49980 into shape (1,765,196)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-0b02cfac7e8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtest_prediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain_modle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtest_prediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_prediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-72-7afce38653a2>\u001b[0m in \u001b[0;36mformat_prediction\u001b[0;34m(prediction, network_info)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     prediction = prediction.reshape((\n\u001b[0;32m---> 20\u001b[0;31m         batch_size, box_attributes * anchor_count, grid_size * grid_size))\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     prediction = prediction.reshape((\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 49980 into shape (1,765,196)"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(\"dog-cycle-car.png\")\n",
    "img = cv2.resize(img, (416, 416)) # resize to the input dimension\n",
    "img_ =  img[:, :, ::-1].transpose((2, 0, 1))  # BGR -> RGB | H X W C -> C X H X W \n",
    "\n",
    "blocks[0]['classes'] = 80 # TODO load from yolo layer\n",
    "\n",
    "test_prediction = main_modle.predict(np.array([img]))\n",
    "test_prediction = format_prediction(test_prediction, blocks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
