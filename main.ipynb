{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-28T06:32:24.416262Z",
     "start_time": "2018-12-28T06:32:24.384180Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('agg')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-28T06:33:59.999324Z",
     "start_time": "2018-12-28T06:33:59.954713Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Conv2D, LeakyReLU, UpSampling2D, InputLayer, Concatenate, Input, merge, concatenate, Lambda, Reshape, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import plot_model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from random import shuffle\n",
    "from time import time\n",
    "\n",
    "from loss import custom_loss\n",
    "from data_processing import get_data, VOCDataGenerator, COCODataGenerator\n",
    "from multi_gpu_chekpoint import MultiGPUCheckpointCallback\n",
    "\n",
    "import pickle\n",
    "\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing the config\n",
    "\n",
    "The network config is in `yolov3.cfg`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-28T06:32:34.647935Z",
     "start_time": "2018-12-28T06:32:34.600741Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_config(cfg_path, verbose=False):\n",
    "    file = open(cfg_path, 'r')\n",
    "    lines = file.readlines()\n",
    "        \n",
    "    # get rid of comments and blank lines and white space\n",
    "    lines = [x for x in lines if len(x) > 1]\n",
    "    lines = [x for x in lines if x[0] != '#']\n",
    "    lines = [x.rstrip().lstrip() for x in lines]\n",
    "\n",
    "    block = {}\n",
    "    blocks = []\n",
    "    \n",
    "    for line in lines:\n",
    "        if verbose: print('valuating line: %s' % line)\n",
    "        \n",
    "        if line[0] == '[': # new block start\n",
    "            if len(block) != 0: # if the block inst empty (has data) then reset it\n",
    "                blocks.append(block)\n",
    "                block = {}\n",
    "                \n",
    "            block['type'] = line[1:-1]\n",
    "        else:\n",
    "            key, value = line.split('=')\n",
    "            key, value = key.rstrip(), value.lstrip()\n",
    "            block[key] = value\n",
    "\n",
    "    blocks += [block]\n",
    "    return blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-28T18:52:21.391899Z",
     "start_time": "2018-12-28T18:52:21.343859Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "blocks = parse_config('hyper.cfg')\n",
    "\n",
    "LABELS = ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n",
    "\n",
    "IMAGE_H, IMAGE_W = 416, 416\n",
    "GRID_H,  GRID_W  = 13 , 13\n",
    "BOX              = 5\n",
    "CLASS            = len(LABELS)\n",
    "CLASS_WEIGHTS    = np.ones(CLASS, dtype='float32')\n",
    "OBJ_THRESHOLD    = 0.3#0.5\n",
    "NMS_THRESHOLD    = 0.3#0.45\n",
    "ANCHORS          = [0.57273, 0.677385, 1.87446, 2.06253, 3.33843, 5.47434, 7.88282, 3.52778, 9.77052, 9.16828]\n",
    "\n",
    "NO_OBJECT_SCALE  = 1.0\n",
    "OBJECT_SCALE     = 5.0\n",
    "COORD_SCALE      = 1.0\n",
    "CLASS_SCALE      = 1.0\n",
    "\n",
    "BATCH_SIZE       = 16\n",
    "WARM_UP_BATCHES  = 3\n",
    "TRUE_BOX_BUFFER  = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix shortcut issue\n",
    "this is a quick fix for the shortcut issue I was running into but I want to figure out why and how this works so I can create a better implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-28T18:52:22.951910Z",
     "start_time": "2018-12-28T18:52:22.905815Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def space_to_depth_x2(x):\n",
    "    return tf.space_to_depth(x, block_size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The model\n",
    "\n",
    "(add specific info about the model)\n",
    "\n",
    "### Questions:\n",
    "1. Why is padding important in a convolutional layer\n",
    "2. What is `BatchNormalization` and why is it important\n",
    "3. What does `bilinear` mean?\n",
    "4. What is `B X C X H X W` and how is it difforent than other formats\n",
    "5. What is the difforence between route and shortcut and how are they implemented?\n",
    "    * see the degradation problem, and an [explaination here](https://www.quora.com/What-are-shortcut-connections-how-do-they-work-and-what-is-their-role-in-the-paper-Deep-Residual-Learning-for-Image-Recognition).\n",
    "6. What does `space_to_depth_x2` do?\n",
    "7. What is `true_boxes` and why is it important?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-28T18:52:25.777245Z",
     "start_time": "2018-12-28T18:52:23.326400Z"
    },
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0/27) processing: convolutional\n",
      "(1/27) processing: maxpooling\n",
      "(2/27) processing: convolutional\n",
      "(3/27) processing: maxpooling\n",
      "(4/27) processing: convolutional\n",
      "(5/27) processing: convolutional\n",
      "(6/27) processing: maxpooling\n",
      "(7/27) processing: convolutional\n",
      "(8/27) processing: maxpooling\n",
      "(9/27) processing: convolutional\n",
      "(10/27) processing: convolutional\n",
      "(11/27) processing: convolutional\n",
      "(12/27) processing: convolutional\n",
      "(13/27) processing: convolutional\n",
      "(14/27) processing: convolutional\n",
      "(15/27) processing: convolutional\n",
      "(16/27) processing: convolutional\n",
      "(17/27) processing: skip_connection\n",
      "(18/27) processing: maxpooling\n",
      "(19/27) processing: convolutional\n",
      "(20/27) processing: convolutional\n",
      "(21/27) processing: convolutional\n",
      "(22/27) processing: skip_connection\n",
      "(23/27) processing: convolutional\n",
      "(24/27) processing: space_to_depth\n",
      "(25/27) processing: concatenate\n",
      "(26/27) processing: convolutional\n",
      "(27/27) processing: net\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 416, 416, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_0 (Conv2D)                 (None, 416, 416, 16) 432         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_0 (BatchNormalizatio (None, 416, 416, 16) 64          conv_0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 416, 416, 16) 0           batch_norm_0[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 208, 208, 16) 0           leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_1 (Conv2D)                 (None, 208, 208, 32) 4608        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_1 (BatchNormalizatio (None, 208, 208, 32) 128         conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 208, 208, 32) 0           batch_norm_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 104, 104, 32) 0           leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_2 (Conv2D)                 (None, 104, 104, 64) 18432       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_2 (BatchNormalizatio (None, 104, 104, 64) 256         conv_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 104, 104, 64) 0           batch_norm_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_3 (Conv2D)                 (None, 104, 104, 128 73728       leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_3 (BatchNormalizatio (None, 104, 104, 128 512         conv_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 104, 104, 128 0           batch_norm_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 52, 52, 128)  0           leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_4 (Conv2D)                 (None, 52, 52, 256)  294912      max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_4 (BatchNormalizatio (None, 52, 52, 256)  1024        conv_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 52, 52, 256)  0           batch_norm_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 26, 26, 256)  0           leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_5 (Conv2D)                 (None, 26, 26, 512)  1179648     max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_5 (BatchNormalizatio (None, 26, 26, 512)  2048        conv_5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 26, 26, 512)  0           batch_norm_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_6 (Conv2D)                 (None, 26, 26, 1024) 4718592     leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_6 (BatchNormalizatio (None, 26, 26, 1024) 4096        conv_6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, 26, 26, 1024) 0           batch_norm_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_7 (Conv2D)                 (None, 26, 26, 256)  262144      leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_7 (BatchNormalizatio (None, 26, 26, 256)  1024        conv_7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, 26, 26, 256)  0           batch_norm_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_8 (Conv2D)                 (None, 26, 26, 512)  1179648     leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_8 (BatchNormalizatio (None, 26, 26, 512)  2048        conv_8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, 26, 26, 512)  0           batch_norm_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_9 (Conv2D)                 (None, 26, 26, 256)  131072      leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_9 (BatchNormalizatio (None, 26, 26, 256)  1024        conv_9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, 26, 26, 256)  0           batch_norm_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_10 (Conv2D)                (None, 26, 26, 256)  65536       leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_10 (BatchNormalizati (None, 26, 26, 256)  1024        conv_10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)      (None, 26, 26, 256)  0           batch_norm_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_11 (Conv2D)                (None, 26, 26, 512)  1179648     leaky_re_lu_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_11 (BatchNormalizati (None, 26, 26, 512)  2048        conv_11[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)      (None, 26, 26, 512)  0           batch_norm_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_12 (Conv2D)                (None, 26, 26, 256)  131072      leaky_re_lu_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_12 (BatchNormalizati (None, 26, 26, 256)  1024        conv_12[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)      (None, 26, 26, 256)  0           batch_norm_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 13, 13, 256)  0           leaky_re_lu_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_13 (Conv2D)                (None, 13, 13, 128)  32768       max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_13 (BatchNormalizati (None, 13, 13, 128)  512         conv_13[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)      (None, 13, 13, 128)  0           batch_norm_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_14 (Conv2D)                (None, 13, 13, 256)  294912      leaky_re_lu_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_14 (BatchNormalizati (None, 13, 13, 256)  1024        conv_14[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_16 (Conv2D)                (None, 26, 26, 64)   16384       leaky_re_lu_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)      (None, 13, 13, 256)  0           batch_norm_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_16 (BatchNormalizati (None, 26, 26, 64)   256         conv_16[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_15 (Conv2D)                (None, 13, 13, 128)  32768       leaky_re_lu_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)      (None, 26, 26, 64)   0           batch_norm_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_15 (BatchNormalizati (None, 13, 13, 128)  512         conv_15[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 13, 13, 256)  0           leaky_re_lu_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)      (None, 13, 13, 128)  0           batch_norm_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 13, 13, 384)  0           lambda_1[0][0]                   \n",
      "                                                                 leaky_re_lu_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_17 (Conv2D)                (None, 13, 13, 256)  884736      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_17 (BatchNormalizati (None, 13, 13, 256)  1024        conv_17[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)      (None, 13, 13, 256)  0           batch_norm_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_18 (Conv2D)                (None, 13, 13, 425)  109225      leaky_re_lu_18[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 10,629,913\n",
      "Trainable params: 10,620,089\n",
      "Non-trainable params: 9,824\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_layer = blocks[0]\n",
    "input_shape = (int(input_layer['shape']), \n",
    "    int(input_layer['shape']), \n",
    "    int(input_layer['channels']))\n",
    "\n",
    "true_boxes = Input(shape=(1, 1, 1, TRUE_BOX_BUFFER , 4))\n",
    "model_input = Input(input_shape)\n",
    "x = model_input\n",
    "\n",
    "skip_connection = None\n",
    "skip_connection_x = None\n",
    "output = None\n",
    "model = None\n",
    "\n",
    "conv_count = 0\n",
    "\n",
    "for index, block in enumerate(blocks[1:]):\n",
    "    print('(%i/%i) processing: %s' % (index, len(blocks) - 2, block['type']))\n",
    "    \n",
    "    if block['type'] == 'convolutional':        \n",
    "        filters = int(block['filters'])\n",
    "        kernel = int(block['kernel'])\n",
    "        strides = int(block['strides'])\n",
    "        \n",
    "        x = Conv2D(filters, \n",
    "                   (kernel, kernel), \n",
    "                   strides=(strides, strides), \n",
    "                   padding='same', \n",
    "                   name='conv_%i' % conv_count,\n",
    "                   use_bias=False)(x)\n",
    "        x = BatchNormalization(name='batch_norm_%i' % conv_count)(x)\n",
    "        x = LeakyReLU(alpha=0.1)(x)\n",
    "        \n",
    "        conv_count += 1\n",
    "        \n",
    "    if block['type'] == 'maxpooling':\n",
    "        pool = int(block['pool'])\n",
    "        \n",
    "        x = MaxPooling2D(pool_size=(pool, pool))(x)\n",
    "        \n",
    "    if block['type'] == 'skip_connection':\n",
    "        open_connection = int(block['open'])\n",
    "        \n",
    "        if open_connection:\n",
    "            skip_connection = x # hold current x for later\n",
    "        else:\n",
    "            skip_connection_x = x # make sure we know what this is for concat\n",
    "            x = skip_connection # set x to skip connect from earlier\n",
    "    \n",
    "    if block['type'] == 'space_to_depth':\n",
    "        x = Lambda(space_to_depth_x2)(x)\n",
    "        \n",
    "    if block['type'] == 'concatenate':\n",
    "        x = concatenate([x, skip_connection_x])\n",
    "        \n",
    "    if block['type'] == 'net':\n",
    "        x = Conv2D(BOX * (4 + 1 + CLASS), \n",
    "            (1, 1), strides=(1, 1), \n",
    "            name='conv_%i' % conv_count, \n",
    "            padding='same')(x)\n",
    "        \n",
    "        x = Model(model_input, x, name='yolo')\n",
    "        x.summary()\n",
    "#         plot_model(x, to_file='doc/yolo_model.png')\n",
    "            \n",
    "        x = x(model_input)\n",
    "        output = Reshape((GRID_H, GRID_W, BOX, 4 + 1 + CLASS))(x)\n",
    "        output = Lambda(lambda a: a[0])([output, true_boxes]) # seems like `true_boxes` is just being removed here\n",
    "        \n",
    "        model = Model([model_input, true_boxes], output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-28T18:52:25.951882Z",
     "start_time": "2018-12-28T18:52:25.780750Z"
    },
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 416, 416, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "yolo (Model)                    (None, 13, 13, 425)  10629913    input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 13, 13, 5, 85 0           yolo[1][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            (None, 1, 1, 1, 10,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 13, 13, 5, 85 0           reshape_1[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 10,629,913\n",
      "Trainable params: 10,620,089\n",
      "Non-trainable params: 9,824\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "# plot_model(model, to_file='doc/model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions\n",
    "Output and generating predictions\n",
    "\n",
    "### Output Tensor\n",
    "![image](https://cdn-images-1.medium.com/max/1600/1*cGfWw6lGmV1xUKRsd--JxQ.png)\n",
    "\n",
    "Each coordinate is represented like this:\n",
    "![image.png](https://blog.paperspace.com/content/images/2018/04/bbox_-2.png)\n",
    "the coordinates are the x, y in the matrix of anchors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T18:53:18.733929Z",
     "start_time": "2018-12-20T18:53:18.729557Z"
    }
   },
   "source": [
    "The above output will need to be changed into a an array like the one in the image above\n",
    "\n",
    "### Questions\n",
    "1. what is the 3rd attribute\n",
    "2. could you use another network to decrease grid size?\n",
    "3. what is this doing? `tf.math.exp(prediction[:, :, 2:4]) * anchors`\n",
    "4. softmax vs sigmoid\n",
    "5. understand the center functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-28T18:46:23.854767Z",
     "start_time": "2018-12-28T18:46:23.793308Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MARK - helper functions\n",
    "def sigmoid(x):\n",
    "    return 1. / (1. + np.exp(-x))\n",
    "\n",
    "\n",
    "def softmax(x, axis=-1, t=-100.):\n",
    "    x = x - np.max(x)\n",
    "    \n",
    "    if np.min(x) < t:\n",
    "        x = x/np.min(x)*t\n",
    "        \n",
    "    e_x = np.exp(x)\n",
    "    \n",
    "    return e_x / e_x.sum(axis, keepdims=True)\n",
    "\n",
    "\n",
    "def center_xy(x, y, grid, row, col):\n",
    "    grid_h, grid_w = grid\n",
    "    \n",
    "    x = (col + sigmoid(x)) / grid_w\n",
    "    y = (row + sigmoid(y)) / grid_h\n",
    "    \n",
    "    return x, y\n",
    "    \n",
    "    \n",
    "def center_hw(h, w, grid, count):\n",
    "    grid_h, grid_w = grid\n",
    "    \n",
    "    # get anchor position (+1 because they are in sets)\n",
    "    w = ANCHORS[2 * count + 0] * np.exp(w) / grid_w\n",
    "    h = ANCHORS[2 * count + 1] * np.exp(h) / grid_h\n",
    "\n",
    "    return h, w\n",
    "\n",
    "# MARK - main function\n",
    "\n",
    "def format_prediction(prediction, threshold=0.3):\n",
    "    \"\"\"\n",
    "    :param network_info: first block\n",
    "    \"\"\"\n",
    "    \n",
    "    h, w, count = prediction.shape[:3]\n",
    "    grid = h, w\n",
    "    \n",
    "    boxes = [] # format: xmin, xmax, ymin, ymax, objectness, classes\n",
    "    prediction[..., 4] = sigmoid(prediction[..., 4]) # normalize\n",
    "    \"\"\"\n",
    "    the next line is a little confusing, basically what it is doing is:\n",
    "        * get all boxes\n",
    "        * expand them\n",
    "        * multiply by classes\n",
    "    \"\"\"\n",
    "    prediction[..., 5:] = prediction[..., 4][..., np.newaxis] * softmax(prediction[..., 5:]) # softmax and unsqueez    \n",
    "    prediction[..., 5:] *= prediction[..., 5:] > threshold # filter classes below threashold\n",
    "    \n",
    "    for i in range(h):\n",
    "        for j in range(w):\n",
    "            for c in range(count):\n",
    "                current_prediction = prediction[i, j, c]\n",
    "                classes = current_prediction[5:]\n",
    "                \n",
    "                if np.sum(classes) != 0.: # see if there are any classes which are not 0.\n",
    "                    x, y, width, height = current_prediction[:4]\n",
    "#                     from IPython.core.debugger import Tracer; Tracer()()\n",
    "                    \n",
    "                    x, y = center_xy(x, y, grid, i, j)\n",
    "                    height, width = center_hw(height, width, grid, c)\n",
    "                    \n",
    "                    xmin = x-width/2\n",
    "                    xmax = x+width/2\n",
    "                    ymin = y-height/2\n",
    "                    ymax = y+height/2\n",
    "                    \n",
    "                    objectness = prediction[i, j, c, 4]\n",
    "                    boxes.append((xmin, xmax, ymin, ymax, objectness, classes))\n",
    "    return boxes\n",
    "\n",
    "# boxes = format_prediction(train_y[201] * 1., threshold=.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-28T18:50:59.905209Z",
     "start_time": "2018-12-28T18:50:59.854883Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "colors = [ # yeah I spent a lot of time picking colors :P\n",
    "    (244, 134, 66),\n",
    "    (66, 134, 244),\n",
    "    (216, 216, 216),\n",
    "    (0, 105, 211), \n",
    "    (0, 28, 55),\n",
    "    (51, 87, 255),\n",
    "    (218, 247, 166),\n",
    "] * CLASS\n",
    "\n",
    "def draw_boxes(image, boxes):\n",
    "    height, width = image.shape[:2]\n",
    "    height_scalar = height / IMAGE_H # get difference scalar\n",
    "    width_scalar = width / IMAGE_W\n",
    "    height_scalar *= IMAGE_H # multiply by height\n",
    "    width_scalar *= IMAGE_W\n",
    "        \n",
    "    for box in boxes:\n",
    "        xmin, xmax, ymin, ymax, objectness, classes = box\n",
    "        xmin = int(xmin * width_scalar)\n",
    "        xmax = int(xmax * width_scalar) \n",
    "        ymin = int(ymin * height_scalar) \n",
    "        ymax = int(ymax * height_scalar)\n",
    "        \n",
    "        main_class = classes.tolist().index(max(classes))\n",
    "        \n",
    "        font = cv2.FONT_HERSHEY_PLAIN\n",
    "        image = cv2.rectangle(image, (xmin, ymin), (xmax, ymax), colors[main_class], 6)\n",
    "                            \n",
    "    return image          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Weights\n",
    "\n",
    "We want to create a class that will allow us to load the weights and read chucks of values.\n",
    "\n",
    "## Questions\n",
    "1. How are weights stored?\n",
    "    _either as pickles or similar_\n",
    "2. beta, gamma, mean, var?\n",
    "3. why is there no bias needed if there are already weights\n",
    "    * I think that maybe what the below if statement does is not check for weights but check for `use_bias` which would explain both things\n",
    "4. does this to check for previos weights or something else? `len(conv_layer.get_weights()) > 1`\n",
    "5. why are the last layer's weights randomized? \n",
    "    * I _think_ this is so that some small training will be able to get a good result\n",
    "6. what would happen if the weights were less precise (ei float16)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-28T18:48:58.656552Z",
     "start_time": "2018-12-28T18:48:58.600964Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class WeightReader:\n",
    "    def __init__(self, file):\n",
    "        self.weights = open(file, 'rb')\n",
    "        self.count = 0\n",
    "        self.headers = np.ndarray(\n",
    "            shape=(4,), dtype='int32', buffer=self.weights.read(16))\n",
    "        \n",
    "    def read(self, size=None):\n",
    "        if size is None:\n",
    "            return self.weights.read()\n",
    "        return self.weights.read(size)\n",
    "    \n",
    "    def read_arr(self, size, shape=None, count_inc=None):\n",
    "        if shape is None:\n",
    "            shape = (size,)\n",
    "            \n",
    "        if count_inc is None:\n",
    "            count_inc = np.prod(shape)\n",
    "        \n",
    "        self.count += count_inc\n",
    "        \n",
    "        return np.ndarray(\n",
    "            shape=shape, dtype='float32', buffer=self.read(size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-28T18:50:31.996940Z",
     "start_time": "2018-12-28T18:48:58.748973Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing index: 0\n",
      "processing index: 1\n",
      "processing index: 2\n",
      "processing index: 3\n",
      "processing index: 4\n",
      "processing index: 5\n",
      "processing index: 6\n",
      "processing index: 7\n",
      "processing index: 8\n",
      "processing index: 9\n",
      "processing index: 10\n",
      "processing index: 11\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "buffer is too small for requested array",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-3f6c43e20c57>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     conv_weights = weight_reader.read_arr(\n\u001b[1;32m---> 38\u001b[1;33m         weights_size * 4, shape=darknet_weight_shape, count_inc=weights_size)\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \"\"\"\n",
      "\u001b[1;32m<ipython-input-10-fa3c8156850d>\u001b[0m in \u001b[0;36mread_arr\u001b[1;34m(self, size, shape, count_inc)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         return np.ndarray(\n\u001b[1;32m---> 23\u001b[1;33m             shape=shape, dtype='float32', buffer=self.read(size))\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: buffer is too small for requested array"
     ]
    }
   ],
   "source": [
    "weight_reader = WeightReader('yolov3-tiny.weights')\n",
    "\n",
    "batch_normalize = True # this would change if we used `use_bias`\n",
    "\n",
    "for index in range(conv_count + 1):\n",
    "    print('processing index: %i' % index)\n",
    "    conv_layer = model.get_layer('yolo').get_layer('conv_%i' % index)\n",
    "    try:\n",
    "        norm_layer = model.get_layer('yolo').get_layer('batch_norm_%i' % index)\n",
    "    except: # TODO this is a hack\n",
    "        batch_normalize = False\n",
    "    \n",
    "    size = conv_layer.kernel.shape[:2]\n",
    "    \n",
    "    filters = conv_layer.filters\n",
    "    conv_bias = weight_reader.read_arr(filters * 4, shape=(filters,))\n",
    "    \n",
    "    if batch_normalize and norm_layer is not None:\n",
    "        batch_weights = weight_reader.read_arr(\n",
    "            filters * 12, shape=(3, filters))\n",
    "        \n",
    "        # this may have issues? (see https://github.com/allanzelener/YAD2K/blob/master/yad2k.py#L144)\n",
    "        batch_weight_list = [\n",
    "            batch_weights[0],  # scale gamma\n",
    "            conv_bias,  # shift beta\n",
    "            batch_weights[1],  # running mean\n",
    "            batch_weights[2]  # running var\n",
    "        ]\n",
    "        \n",
    "        norm_layer.set_weights(batch_weight_list)\n",
    "        \n",
    "    last_layer_shape = conv_layer.input_shape\n",
    "    weights_shape = (*size, last_layer_shape[-1], filters)\n",
    "    darknet_weight_shape = (filters, weights_shape[2], *size)\n",
    "    weights_size = np.product(weights_shape)\n",
    "    \n",
    "    conv_weights = weight_reader.read_arr(\n",
    "        weights_size * 4, shape=darknet_weight_shape, count_inc=weights_size)\n",
    "    \n",
    "    \"\"\"\n",
    "    darknet serialization: (out_dim, in_dim, height, width)\n",
    "    tensorflow serialization: (height, width, in_dim, out_dim)\n",
    "    \"\"\"\n",
    "    conv_weights = np.transpose(conv_weights, [2, 3, 1, 0])\n",
    "    conv_weights = [conv_weights] if batch_normalize else [\n",
    "        conv_weights, conv_bias\n",
    "    ]\n",
    "    \n",
    "    conv_layer.set_weights(conv_weights)\n",
    "\n",
    "print('remaining weights: %f' % (len(weight_reader.read()) / 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-28T18:51:07.150114Z",
     "start_time": "2018-12-28T18:51:03.223443Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average time 0.185862 seconds\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot convert float NaN to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-46949d811065>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mboxes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mformat_prediction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_prediction\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdraw_boxes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mboxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'doc/example.png'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-54e944f11efa>\u001b[0m in \u001b[0;36mdraw_boxes\u001b[1;34m(image, boxes)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mbox\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mboxes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mxmin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxmax\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mymin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mymax\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobjectness\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbox\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mxmin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxmin\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mwidth_scalar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[0mxmax\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxmax\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mwidth_scalar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mymin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mymin\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mheight_scalar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot convert float NaN to integer"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(\"dog-cycle-car.png\")\n",
    "img_input = cv2.resize(img, (416, 416)) # resize to the input dimension\n",
    "img_input = img_input / 255\n",
    "img_input = img_input[..., ::-1]\n",
    "img_input = np.array([img_input])\n",
    "\n",
    "dummy_array = np.zeros((1, 1, 1, 1, TRUE_BOX_BUFFER, 4))\n",
    "\n",
    "times = []\n",
    "for _ in range(10):\n",
    "    start = time()\n",
    "    test_prediction = model.predict([img_input, dummy_array])\n",
    "    times += [time() - start]\n",
    "\n",
    "print('average time %f seconds' % (sum(times) / len(times)))\n",
    "\n",
    "boxes = format_prediction(test_prediction[0], threshold=0.1)\n",
    "img = draw_boxes(img, boxes)\n",
    "plt.imshow(img[..., ::-1])\n",
    "cv2.imwrite('doc/example.png',img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom loss (loss.py)\n",
    "**TODO** write this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the network\n",
    "\n",
    "### Questions\n",
    "1. Why does `exploding gradient` problem happen? Why does clipping values fix it\n",
    "2. Warm up epochs? Turns out the person who implemented them in the loss function doesnt know how or why they are there -- figure out why they need to be here (kinda part of loss)\n",
    "    * they allow the network to train more agresively and ignore certain factors (hight and widht I think) so they \"learn the data\" more quickly before it starts more precice training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data\n",
    "\n",
    "Load the images from the bloodcells dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-28T18:59:13.186828Z",
     "start_time": "2018-12-28T18:52:55.330110Z"
    },
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-Processing (1000) annotations...\n",
      "Done 0.000000\n",
      "Done 0.100000\n",
      "Done 0.200000\n",
      "Done 0.300000\n"
     ]
    }
   ],
   "source": [
    "# model.get_layer('yolo').load_weights('model_weights.h5')\n",
    "\n",
    "# clipvalue=1, clipnorm=1 is for the exploding gradient problem\n",
    "optimizer = Adam(lr=0.5e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0, clipvalue=1., clipnorm=1.)\n",
    "model.compile(loss=custom_loss, optimizer=optimizer) # , metrics=['accuracy']\n",
    "\n",
    "training_generator = COCODataGenerator()\n",
    "\n",
    "for i in range(1):\n",
    "    model.fit_generator(generator=training_generator,\n",
    "                    # validation_data=validation_generator,\n",
    "                    epochs=15,\n",
    "                    use_multiprocessing=False,\n",
    "                    workers=32)\n",
    "\n",
    "    model.get_layer('yolo').save_weights('weights/model_weights.h5', overwrite=True)\n",
    "    model.save('weights/full_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.get_layer('yolo').save_weights('model_weights.h5', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-28T18:59:32.876553Z",
     "start_time": "2018-12-28T18:59:29.065544Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-baef820cf5dc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_x\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mimg_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mimg_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mimg_input\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdummy_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTRUE_BOX_BUFFER\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_x' is not defined"
     ]
    }
   ],
   "source": [
    "img = test_x[5]\n",
    "img_input = img[..., ::-1]\n",
    "img_input = np.array([img_input])\n",
    "\n",
    "dummy_array = np.zeros((1, 1, 1, 1, TRUE_BOX_BUFFER, 4))\n",
    "\n",
    "test_prediction = model.predict([img_input, dummy_array])\n",
    "\n",
    "boxes = format_prediction(test_prediction[0], threshold=.13)\n",
    "# print(boxes)\n",
    "\n",
    "img = draw_boxes((img * 255).astype(np.uint8).copy() , boxes)\n",
    "img = img[..., ::-1]\n",
    "\n",
    "plt.imshow(img)\n",
    "# cv2.imwrite('cell.png',img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
