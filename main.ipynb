{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-01T21:23:10.017856Z",
     "start_time": "2019-01-01T21:23:09.955858Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('agg')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-01T21:24:19.226296Z",
     "start_time": "2019-01-01T21:24:19.178949Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Conv2D, LeakyReLU, UpSampling2D, InputLayer, Concatenate, Input, merge, concatenate, Lambda, Reshape, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import plot_model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from random import shuffle\n",
    "from time import time\n",
    "\n",
    "from loss import custom_loss\n",
    "from data_processing import get_data, BrawlDataGenerator\n",
    "from multi_gpu_chekpoint import MultiGPUCheckpointCallback\n",
    "\n",
    "import pickle\n",
    "\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing the config\n",
    "\n",
    "The network config is in `yolov3.cfg`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-01T21:23:10.849990Z",
     "start_time": "2019-01-01T21:23:10.800981Z"
    }
   },
   "outputs": [],
   "source": [
    "def parse_config(cfg_path, verbose=False):\n",
    "    file = open(cfg_path, 'r')\n",
    "    lines = file.readlines()\n",
    "        \n",
    "    # get rid of comments and blank lines and white space\n",
    "    lines = [x for x in lines if len(x) > 1]\n",
    "    lines = [x for x in lines if x[0] != '#']\n",
    "    lines = [x.rstrip().lstrip() for x in lines]\n",
    "\n",
    "    block = {}\n",
    "    blocks = []\n",
    "    \n",
    "    for line in lines:\n",
    "        if verbose: print('valuating line: %s' % line)\n",
    "        \n",
    "        if line[0] == '[': # new block start\n",
    "            if len(block) != 0: # if the block inst empty (has data) then reset it\n",
    "                blocks.append(block)\n",
    "                block = {}\n",
    "                \n",
    "            block['type'] = line[1:-1]\n",
    "        else:\n",
    "            key, value = line.split('=')\n",
    "            key, value = key.rstrip(), value.lstrip()\n",
    "            block[key] = value\n",
    "\n",
    "    blocks += [block]\n",
    "    return blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-01T21:23:11.125722Z",
     "start_time": "2019-01-01T21:23:11.077073Z"
    }
   },
   "outputs": [],
   "source": [
    "blocks = parse_config('hyper.cfg')\n",
    "\n",
    "LABELS = ['red', 'move_stick']\n",
    "\n",
    "IMAGE_H, IMAGE_W = 416, 416\n",
    "GRID_H,  GRID_W  = 13 , 13\n",
    "BOX              = 5\n",
    "CLASS            = len(LABELS)\n",
    "CLASS_WEIGHTS    = np.ones(CLASS, dtype='float32')\n",
    "OBJ_THRESHOLD    = 0.3#0.5\n",
    "NMS_THRESHOLD    = 0.3#0.45\n",
    "ANCHORS          = [0.57273, 0.677385, 1.87446, 2.06253, 3.33843, 5.47434, 7.88282, 3.52778, 9.77052, 9.16828]\n",
    "\n",
    "NO_OBJECT_SCALE  = 1.0\n",
    "OBJECT_SCALE     = 5.0\n",
    "COORD_SCALE      = 1.0\n",
    "CLASS_SCALE      = 1.0\n",
    "\n",
    "BATCH_SIZE       = 16\n",
    "WARM_UP_BATCHES  = 3\n",
    "TRUE_BOX_BUFFER  = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix shortcut issue\n",
    "this is a quick fix for the shortcut issue I was running into but I want to figure out why and how this works so I can create a better implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-01T21:23:13.339329Z",
     "start_time": "2019-01-01T21:23:13.292990Z"
    }
   },
   "outputs": [],
   "source": [
    "def space_to_depth_x2(x):\n",
    "    return tf.space_to_depth(x, block_size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The model\n",
    "\n",
    "(add specific info about the model)\n",
    "\n",
    "### Questions:\n",
    "1. Why is padding important in a convolutional layer\n",
    "2. What is `BatchNormalization` and why is it important\n",
    "3. What does `bilinear` mean?\n",
    "4. What is `B X C X H X W` and how is it difforent than other formats\n",
    "5. What is the difforence between route and shortcut and how are they implemented?\n",
    "    * see the degradation problem, and an [explaination here](https://www.quora.com/What-are-shortcut-connections-how-do-they-work-and-what-is-their-role-in-the-paper-Deep-Residual-Learning-for-Image-Recognition).\n",
    "6. What does `space_to_depth_x2` do?\n",
    "7. What is `true_boxes` and why is it important?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-01T21:23:16.137637Z",
     "start_time": "2019-01-01T21:23:14.414279Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0/27) processing: convolutional\n",
      "(1/27) processing: maxpooling\n",
      "(2/27) processing: convolutional\n",
      "(3/27) processing: maxpooling\n",
      "(4/27) processing: convolutional\n",
      "(5/27) processing: convolutional\n",
      "(6/27) processing: maxpooling\n",
      "(7/27) processing: convolutional\n",
      "(8/27) processing: maxpooling\n",
      "(9/27) processing: convolutional\n",
      "(10/27) processing: convolutional\n",
      "(11/27) processing: convolutional\n",
      "(12/27) processing: convolutional\n",
      "(13/27) processing: convolutional\n",
      "(14/27) processing: convolutional\n",
      "(15/27) processing: convolutional\n",
      "(16/27) processing: convolutional\n",
      "(17/27) processing: skip_connection\n",
      "(18/27) processing: maxpooling\n",
      "(19/27) processing: convolutional\n",
      "(20/27) processing: convolutional\n",
      "(21/27) processing: convolutional\n",
      "(22/27) processing: skip_connection\n",
      "(23/27) processing: convolutional\n",
      "(24/27) processing: space_to_depth\n",
      "(25/27) processing: concatenate\n",
      "(26/27) processing: convolutional\n",
      "(27/27) processing: net\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_14 (InputLayer)            (None, 416, 416, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv_0 (Conv2D)                  (None, 416, 416, 16)  432         input_14[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_norm_0 (BatchNormalization (None, 416, 416, 16)  64          conv_0[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_129 (LeakyReLU)      (None, 416, 416, 16)  0           batch_norm_0[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_31 (MaxPooling2D)  (None, 208, 208, 16)  0           leaky_re_lu_129[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv_1 (Conv2D)                  (None, 208, 208, 32)  4608        max_pooling2d_31[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batch_norm_1 (BatchNormalization (None, 208, 208, 32)  128         conv_1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_130 (LeakyReLU)      (None, 208, 208, 32)  0           batch_norm_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_32 (MaxPooling2D)  (None, 104, 104, 32)  0           leaky_re_lu_130[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv_2 (Conv2D)                  (None, 104, 104, 64)  18432       max_pooling2d_32[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batch_norm_2 (BatchNormalization (None, 104, 104, 64)  256         conv_2[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_131 (LeakyReLU)      (None, 104, 104, 64)  0           batch_norm_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "conv_3 (Conv2D)                  (None, 104, 104, 128) 73728       leaky_re_lu_131[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_norm_3 (BatchNormalization (None, 104, 104, 128) 512         conv_3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_132 (LeakyReLU)      (None, 104, 104, 128) 0           batch_norm_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_33 (MaxPooling2D)  (None, 52, 52, 128)   0           leaky_re_lu_132[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv_4 (Conv2D)                  (None, 52, 52, 256)   294912      max_pooling2d_33[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batch_norm_4 (BatchNormalization (None, 52, 52, 256)   1024        conv_4[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_133 (LeakyReLU)      (None, 52, 52, 256)   0           batch_norm_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_34 (MaxPooling2D)  (None, 26, 26, 256)   0           leaky_re_lu_133[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv_5 (Conv2D)                  (None, 26, 26, 512)   1179648     max_pooling2d_34[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batch_norm_5 (BatchNormalization (None, 26, 26, 512)   2048        conv_5[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_134 (LeakyReLU)      (None, 26, 26, 512)   0           batch_norm_5[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "conv_6 (Conv2D)                  (None, 26, 26, 1024)  4718592     leaky_re_lu_134[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_norm_6 (BatchNormalization (None, 26, 26, 1024)  4096        conv_6[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_135 (LeakyReLU)      (None, 26, 26, 1024)  0           batch_norm_6[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "conv_7 (Conv2D)                  (None, 26, 26, 256)   262144      leaky_re_lu_135[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_norm_7 (BatchNormalization (None, 26, 26, 256)   1024        conv_7[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_136 (LeakyReLU)      (None, 26, 26, 256)   0           batch_norm_7[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "conv_8 (Conv2D)                  (None, 26, 26, 512)   1179648     leaky_re_lu_136[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_norm_8 (BatchNormalization (None, 26, 26, 512)   2048        conv_8[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_137 (LeakyReLU)      (None, 26, 26, 512)   0           batch_norm_8[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "conv_9 (Conv2D)                  (None, 26, 26, 256)   131072      leaky_re_lu_137[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_norm_9 (BatchNormalization (None, 26, 26, 256)   1024        conv_9[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_138 (LeakyReLU)      (None, 26, 26, 256)   0           batch_norm_9[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "conv_10 (Conv2D)                 (None, 26, 26, 256)   65536       leaky_re_lu_138[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_norm_10 (BatchNormalizatio (None, 26, 26, 256)   1024        conv_10[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_139 (LeakyReLU)      (None, 26, 26, 256)   0           batch_norm_10[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv_11 (Conv2D)                 (None, 26, 26, 512)   1179648     leaky_re_lu_139[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_norm_11 (BatchNormalizatio (None, 26, 26, 512)   2048        conv_11[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_140 (LeakyReLU)      (None, 26, 26, 512)   0           batch_norm_11[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv_12 (Conv2D)                 (None, 26, 26, 256)   131072      leaky_re_lu_140[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_norm_12 (BatchNormalizatio (None, 26, 26, 256)   1024        conv_12[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_141 (LeakyReLU)      (None, 26, 26, 256)   0           batch_norm_12[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_35 (MaxPooling2D)  (None, 13, 13, 256)   0           leaky_re_lu_141[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv_13 (Conv2D)                 (None, 13, 13, 128)   32768       max_pooling2d_35[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batch_norm_13 (BatchNormalizatio (None, 13, 13, 128)   512         conv_13[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_142 (LeakyReLU)      (None, 13, 13, 128)   0           batch_norm_13[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv_14 (Conv2D)                 (None, 13, 13, 256)   294912      leaky_re_lu_142[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_norm_14 (BatchNormalizatio (None, 13, 13, 256)   1024        conv_14[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv_16 (Conv2D)                 (None, 26, 26, 64)    16384       leaky_re_lu_141[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_143 (LeakyReLU)      (None, 13, 13, 256)   0           batch_norm_14[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_norm_16 (BatchNormalizatio (None, 26, 26, 64)    256         conv_16[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv_15 (Conv2D)                 (None, 13, 13, 128)   32768       leaky_re_lu_143[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_145 (LeakyReLU)      (None, 26, 26, 64)    0           batch_norm_16[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_norm_15 (BatchNormalizatio (None, 13, 13, 128)   512         conv_15[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)               (None, 13, 13, 256)   0           leaky_re_lu_145[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_144 (LeakyReLU)      (None, 13, 13, 128)   0           batch_norm_15[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)      (None, 13, 13, 384)   0           lambda_13[0][0]                  \n",
      "                                                                   leaky_re_lu_144[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv_17 (Conv2D)                 (None, 13, 13, 256)   884736      concatenate_7[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_norm_17 (BatchNormalizatio (None, 13, 13, 256)   1024        conv_17[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_146 (LeakyReLU)      (None, 13, 13, 256)   0           batch_norm_17[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv_18 (Conv2D)                 (None, 13, 13, 35)    8995        leaky_re_lu_146[0][0]            \n",
      "====================================================================================================\n",
      "Total params: 10,529,683\n",
      "Trainable params: 10,519,859\n",
      "Non-trainable params: 9,824\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_layer = blocks[0]\n",
    "input_shape = (int(input_layer['shape']), \n",
    "    int(input_layer['shape']), \n",
    "    int(input_layer['channels']))\n",
    "\n",
    "true_boxes = Input(shape=(1, 1, 1, TRUE_BOX_BUFFER , 4))\n",
    "model_input = Input(input_shape)\n",
    "x = model_input\n",
    "\n",
    "skip_connection = None\n",
    "skip_connection_x = None\n",
    "output = None\n",
    "model = None\n",
    "\n",
    "conv_count = 0\n",
    "\n",
    "for index, block in enumerate(blocks[1:]):\n",
    "    print('(%i/%i) processing: %s' % (index, len(blocks) - 2, block['type']))\n",
    "    \n",
    "    if block['type'] == 'convolutional':        \n",
    "        filters = int(block['filters'])\n",
    "        kernel = int(block['kernel'])\n",
    "        strides = int(block['strides'])\n",
    "        \n",
    "        x = Conv2D(filters, \n",
    "                   (kernel, kernel), \n",
    "                   strides=(strides, strides), \n",
    "                   padding='same', \n",
    "                   name='conv_%i' % conv_count,\n",
    "                   use_bias=False)(x)\n",
    "        x = BatchNormalization(name='batch_norm_%i' % conv_count)(x)\n",
    "        x = LeakyReLU(alpha=0.1)(x)\n",
    "        \n",
    "        conv_count += 1\n",
    "        \n",
    "    if block['type'] == 'maxpooling':\n",
    "        pool = int(block['pool'])\n",
    "        \n",
    "        x = MaxPooling2D(pool_size=(pool, pool))(x)\n",
    "        \n",
    "    if block['type'] == 'skip_connection':\n",
    "        open_connection = int(block['open'])\n",
    "        \n",
    "        if open_connection:\n",
    "            skip_connection = x # hold current x for later\n",
    "        else:\n",
    "            skip_connection_x = x # make sure we know what this is for concat\n",
    "            x = skip_connection # set x to skip connect from earlier\n",
    "    \n",
    "    if block['type'] == 'space_to_depth':\n",
    "        x = Lambda(space_to_depth_x2)(x)\n",
    "        \n",
    "    if block['type'] == 'concatenate':\n",
    "        x = concatenate([x, skip_connection_x])\n",
    "        \n",
    "    if block['type'] == 'net':\n",
    "        x = Conv2D(BOX * (4 + 1 + CLASS), \n",
    "            (1, 1), strides=(1, 1), \n",
    "            name='conv_%i' % conv_count, \n",
    "            padding='same')(x)\n",
    "        \n",
    "        x = Model(model_input, x, name='yolo')\n",
    "        x.summary()\n",
    "#         plot_model(x, to_file='doc/yolo_model.png')\n",
    "            \n",
    "        x = x(model_input)\n",
    "        output = Reshape((GRID_H, GRID_W, BOX, 4 + 1 + CLASS))(x)\n",
    "        output = Lambda(lambda a: a[0])([output, true_boxes]) # seems like `true_boxes` is just being removed here\n",
    "        \n",
    "        model = Model([model_input, true_boxes], output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-01T21:23:16.191673Z",
     "start_time": "2019-01-01T21:23:16.140197Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_14 (InputLayer)            (None, 416, 416, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "yolo (Model)                     (None, 13, 13, 35)    10529683    input_14[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "reshape_7 (Reshape)              (None, 13, 13, 5, 7)  0           yolo[1][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "input_13 (InputLayer)            (None, 1, 1, 1, 10, 4 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_14 (Lambda)               (None, 13, 13, 5, 7)  0           reshape_7[0][0]                  \n",
      "                                                                   input_13[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 10,529,683\n",
      "Trainable params: 10,519,859\n",
      "Non-trainable params: 9,824\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "# plot_model(model, to_file='doc/model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions\n",
    "Output and generating predictions\n",
    "\n",
    "### Output Tensor\n",
    "![image](https://cdn-images-1.medium.com/max/1600/1*cGfWw6lGmV1xUKRsd--JxQ.png)\n",
    "\n",
    "Each coordinate is represented like this:\n",
    "![image.png](https://blog.paperspace.com/content/images/2018/04/bbox_-2.png)\n",
    "the coordinates are the x, y in the matrix of anchors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T18:53:18.733929Z",
     "start_time": "2018-12-20T18:53:18.729557Z"
    }
   },
   "source": [
    "The above output will need to be changed into a an array like the one in the image above\n",
    "\n",
    "### Questions\n",
    "1. what is the 3rd attribute\n",
    "2. could you use another network to decrease grid size?\n",
    "3. what is this doing? `tf.math.exp(prediction[:, :, 2:4]) * anchors`\n",
    "4. softmax vs sigmoid\n",
    "5. understand the center functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-01T21:23:16.253172Z",
     "start_time": "2019-01-01T21:23:16.194026Z"
    }
   },
   "outputs": [],
   "source": [
    "# MARK - helper functions\n",
    "def sigmoid(x):\n",
    "    return 1. / (1. + np.exp(-x))\n",
    "\n",
    "\n",
    "def softmax(x, axis=-1, t=-100.):\n",
    "    x = x - np.max(x)\n",
    "    \n",
    "    if np.min(x) < t:\n",
    "        x = x/np.min(x)*t\n",
    "        \n",
    "    e_x = np.exp(x)\n",
    "    \n",
    "    return e_x / e_x.sum(axis, keepdims=True)\n",
    "\n",
    "\n",
    "def center_xy(x, y, grid, row, col):\n",
    "    grid_h, grid_w = grid\n",
    "    \n",
    "    x = (col + sigmoid(x)) / grid_w\n",
    "    y = (row + sigmoid(y)) / grid_h\n",
    "    \n",
    "    return x, y\n",
    "    \n",
    "    \n",
    "def center_hw(h, w, grid, count):\n",
    "    grid_h, grid_w = grid\n",
    "    \n",
    "    # get anchor position (+1 because they are in sets)\n",
    "    w = ANCHORS[2 * count + 0] * np.exp(w) / grid_w\n",
    "    h = ANCHORS[2 * count + 1] * np.exp(h) / grid_h\n",
    "\n",
    "    return h, w\n",
    "\n",
    "# MARK - main function\n",
    "\n",
    "def format_prediction(prediction, threshold=0.3):\n",
    "    \"\"\"\n",
    "    :param network_info: first block\n",
    "    \"\"\"\n",
    "    \n",
    "    h, w, count = prediction.shape[:3]\n",
    "    grid = h, w\n",
    "    \n",
    "    boxes = [] # format: xmin, xmax, ymin, ymax, objectness, classes\n",
    "    prediction[..., 4] = sigmoid(prediction[..., 4]) # normalize\n",
    "    \"\"\"\n",
    "    the next line is a little confusing, basically what it is doing is:\n",
    "        * get all boxes\n",
    "        * expand them\n",
    "        * multiply by classes\n",
    "    \"\"\"\n",
    "    prediction[..., 5:] = prediction[..., 4][..., np.newaxis] * softmax(prediction[..., 5:]) # softmax and unsqueez    \n",
    "    prediction[..., 5:] *= prediction[..., 5:] > threshold # filter classes below threashold\n",
    "    \n",
    "    for i in range(h):\n",
    "        for j in range(w):\n",
    "            for c in range(count):\n",
    "                current_prediction = prediction[i, j, c]\n",
    "                classes = current_prediction[5:]\n",
    "                \n",
    "                if np.sum(classes) != 0.: # see if there are any classes which are not 0.\n",
    "                    x, y, width, height = current_prediction[:4]\n",
    "#                     from IPython.core.debugger import Tracer; Tracer()()\n",
    "                    \n",
    "                    x, y = center_xy(x, y, grid, i, j)\n",
    "                    height, width = center_hw(height, width, grid, c)\n",
    "                    \n",
    "                    xmin = x-width/2\n",
    "                    xmax = x+width/2\n",
    "                    ymin = y-height/2\n",
    "                    ymax = y+height/2\n",
    "                    \n",
    "                    objectness = prediction[i, j, c, 4]\n",
    "                    boxes.append((xmin, xmax, ymin, ymax, objectness, classes))\n",
    "    return boxes\n",
    "\n",
    "# boxes = format_prediction(train_y[201] * 1., threshold=.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-01T21:23:16.302169Z",
     "start_time": "2019-01-01T21:23:16.256215Z"
    }
   },
   "outputs": [],
   "source": [
    "colors = [ # yeah I spent a lot of time picking colors :P\n",
    "    (244, 134, 66),\n",
    "    (66, 134, 244),\n",
    "    (216, 216, 216),\n",
    "    (0, 105, 211), \n",
    "    (0, 28, 55),\n",
    "    (51, 87, 255),\n",
    "    (218, 247, 166),\n",
    "] * CLASS\n",
    "\n",
    "def draw_boxes(image, boxes):\n",
    "    height, width = image.shape[:2]\n",
    "    height_scalar = height / IMAGE_H # get difference scalar\n",
    "    width_scalar = width / IMAGE_W\n",
    "    height_scalar *= IMAGE_H # multiply by height\n",
    "    width_scalar *= IMAGE_W\n",
    "        \n",
    "    for box in boxes:\n",
    "        xmin, xmax, ymin, ymax, objectness, classes = box\n",
    "        xmin = int(xmin * width_scalar)\n",
    "        xmax = int(xmax * width_scalar) \n",
    "        ymin = int(ymin * height_scalar) \n",
    "        ymax = int(ymax * height_scalar)\n",
    "        \n",
    "        main_class = classes.tolist().index(max(classes))\n",
    "        \n",
    "        font = cv2.FONT_HERSHEY_PLAIN\n",
    "        image = cv2.rectangle(image, (xmin, ymin), (xmax, ymax), colors[main_class], 6)\n",
    "                            \n",
    "    return image          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Weights\n",
    "\n",
    "We want to create a class that will allow us to load the weights and read chucks of values.\n",
    "\n",
    "## Questions\n",
    "1. How are weights stored?\n",
    "    _either as pickles or similar_\n",
    "2. beta, gamma, mean, var?\n",
    "3. why is there no bias needed if there are already weights\n",
    "    * I think that maybe what the below if statement does is not check for weights but check for `use_bias` which would explain both things\n",
    "4. does this to check for previos weights or something else? `len(conv_layer.get_weights()) > 1`\n",
    "5. why are the last layer's weights randomized? \n",
    "    * I _think_ this is so that some small training will be able to get a good result\n",
    "6. what would happen if the weights were less precise (ei float16)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-01T21:23:16.897600Z",
     "start_time": "2019-01-01T21:23:16.849628Z"
    }
   },
   "outputs": [],
   "source": [
    "class WeightReader:\n",
    "    def __init__(self, file):\n",
    "        self.weights = open(file, 'rb')\n",
    "        self.count = 0\n",
    "        self.headers = np.ndarray(\n",
    "            shape=(4,), dtype='int32', buffer=self.weights.read(16))\n",
    "        \n",
    "    def read(self, size=None):\n",
    "        if size is None:\n",
    "            return self.weights.read()\n",
    "        return self.weights.read(size)\n",
    "    \n",
    "    def read_arr(self, size, shape=None, count_inc=None):\n",
    "        if shape is None:\n",
    "            shape = (size,)\n",
    "            \n",
    "        if count_inc is None:\n",
    "            count_inc = np.prod(shape)\n",
    "        \n",
    "        self.count += count_inc\n",
    "        \n",
    "        return np.ndarray(\n",
    "            shape=shape, dtype='float32', buffer=self.read(size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-01T21:24:09.819924Z",
     "start_time": "2019-01-01T21:23:17.344466Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remaining weights: 40453878.000000\n"
     ]
    }
   ],
   "source": [
    "weight_reader = WeightReader('yolo.weights')\n",
    "\n",
    "batch_normalize = True # this would change if we used `use_bias`\n",
    "\n",
    "for index in range(conv_count + 1):\n",
    "    conv_layer = model.get_layer('yolo').get_layer('conv_%i' % index)\n",
    "    try:\n",
    "        norm_layer = model.get_layer('yolo').get_layer('batch_norm_%i' % index)\n",
    "    except: # TODO this is a hack\n",
    "        batch_normalize = False\n",
    "    \n",
    "    size = conv_layer.kernel.shape[:2]\n",
    "    \n",
    "    filters = conv_layer.filters\n",
    "    conv_bias = weight_reader.read_arr(filters * 4, shape=(filters,))\n",
    "    \n",
    "    if batch_normalize and norm_layer is not None:\n",
    "        batch_weights = weight_reader.read_arr(\n",
    "            filters * 12, shape=(3, filters))\n",
    "        \n",
    "        # this may have issues? (see https://github.com/allanzelener/YAD2K/blob/master/yad2k.py#L144)\n",
    "        batch_weight_list = [\n",
    "            batch_weights[0],  # scale gamma\n",
    "            conv_bias,  # shift beta\n",
    "            batch_weights[1],  # running mean\n",
    "            batch_weights[2]  # running var\n",
    "        ]\n",
    "        \n",
    "        norm_layer.set_weights(batch_weight_list)\n",
    "        \n",
    "    last_layer_shape = conv_layer.input_shape\n",
    "    weights_shape = (*size, last_layer_shape[-1], filters)\n",
    "    darknet_weight_shape = (filters, weights_shape[2], *size)\n",
    "    weights_size = np.product(weights_shape)\n",
    "    \n",
    "    conv_weights = weight_reader.read_arr(\n",
    "        weights_size * 4, shape=darknet_weight_shape, count_inc=weights_size)\n",
    "    \n",
    "    \"\"\"\n",
    "    darknet serialization: (out_dim, in_dim, height, width)\n",
    "    tensorflow serialization: (height, width, in_dim, out_dim)\n",
    "    \"\"\"\n",
    "    conv_weights = np.transpose(conv_weights, [2, 3, 1, 0])\n",
    "    conv_weights = [conv_weights] if batch_normalize else [\n",
    "        conv_weights, conv_bias\n",
    "    ]\n",
    "    \n",
    "    conv_layer.set_weights(conv_weights)\n",
    "\n",
    "print('remaining weights: %f' % (len(weight_reader.read()) / 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-01T21:24:27.547864Z",
     "start_time": "2019-01-01T21:24:23.663176Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average time 0.375875 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/numpy/core/fromnumeric.py:83: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:54: RuntimeWarning: invalid value encountered in greater\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot convert float NaN to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-8ccd5eadb3fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mboxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_prediction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdraw_boxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'doc/example.png'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-91-1f8bcb547d64>\u001b[0m in \u001b[0;36mdraw_boxes\u001b[0;34m(image, boxes)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbox\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mboxes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mxmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mymin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mymax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobjectness\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mxmin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxmin\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mwidth_scalar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mxmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxmax\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mwidth_scalar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mymin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mymin\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mheight_scalar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot convert float NaN to integer"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(\"dog-cycle-car.png\")\n",
    "img_input = cv2.resize(img, (416, 416)) # resize to the input dimension\n",
    "img_input = img_input / 255\n",
    "img_input = img_input[..., ::-1]\n",
    "img_input = np.array([img_input])\n",
    "\n",
    "dummy_array = np.zeros((1, 1, 1, 1, TRUE_BOX_BUFFER, 4))\n",
    "\n",
    "times = []\n",
    "for _ in range(10):\n",
    "    start = time()\n",
    "    test_prediction = model.predict([img_input, dummy_array])\n",
    "    times += [time() - start]\n",
    "\n",
    "print('average time %f seconds' % (sum(times) / len(times)))\n",
    "\n",
    "boxes = format_prediction(test_prediction[0], threshold=0.1)\n",
    "img = draw_boxes(img, boxes)\n",
    "plt.imshow(img[..., ::-1])\n",
    "cv2.imwrite('doc/example.png',img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom loss (loss.py)\n",
    "**TODO** write this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the network\n",
    "\n",
    "### Questions\n",
    "1. Why does `exploding gradient` problem happen? Why does clipping values fix it\n",
    "2. Warm up epochs? Turns out the person who implemented them in the loss function doesnt know how or why they are there -- figure out why they need to be here (kinda part of loss)\n",
    "    * they allow the network to train more agresively and ignore certain factors (hight and widht I think) so they \"learn the data\" more quickly before it starts more precice training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data\n",
    "\n",
    "Load the images from the bloodcells dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-01T21:27:12.592207Z",
     "start_time": "2019-01-01T21:26:54.855120Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "indices[0,12,0,0] = 1 is not in [0, 1)\n\t [[node loss_7/lambda_14_loss/GatherV2 (defined at /Users/zoe/robotics/brawl/yolo/loss.py:134)  = GatherV2[Taxis=DT_INT32, Tindices=DT_INT64, Tparams=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](training_4/Adam/gradients/loss_7/lambda_14_loss/Mean_2_grad/Reshape, loss_7/lambda_14_loss/ArgMax, loss_7/lambda_14_loss/GatherV2/axis)]]\n\nCaused by op 'loss_7/lambda_14_loss/GatherV2', defined at:\n  File \"/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/asyncio/base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/usr/local/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/usr/local/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n    self.run()\n  File \"/usr/local/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/usr/local/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/usr/local/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/usr/local/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n    return runner(coro)\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-101-17673d0b006b>\", line 5, in <module>\n    model.compile(loss=custom_loss, optimizer=optimizer) # , metrics=['accuracy']\n  File \"/usr/local/lib/python3.6/site-packages/keras/engine/training.py\", line 850, in compile\n    sample_weight, mask)\n  File \"/usr/local/lib/python3.6/site-packages/keras/engine/training.py\", line 450, in weighted\n    score_array = fn(y_true, y_pred)\n  File \"/Users/zoe/robotics/brawl/yolo/loss.py\", line 134, in custom_loss\n    class_mask = y_true[..., 4] * tf.gather(CLASS_WEIGHTS, true_box_class) * CLASS_SCALE\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 2675, in gather\n    return gen_array_ops.gather_v2(params, indices, axis, name=name)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 3332, in gather_v2\n    \"GatherV2\", params=params, indices=indices, axis=axis, name=name)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): indices[0,12,0,0] = 1 is not in [0, 1)\n\t [[node loss_7/lambda_14_loss/GatherV2 (defined at /Users/zoe/robotics/brawl/yolo/loss.py:134)  = GatherV2[Taxis=DT_INT32, Tindices=DT_INT64, Tparams=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](training_4/Adam/gradients/loss_7/lambda_14_loss/Mean_2_grad/Reshape, loss_7/lambda_14_loss/ArgMax, loss_7/lambda_14_loss/GatherV2/axis)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: indices[0,12,0,0] = 1 is not in [0, 1)\n\t [[{{node loss_7/lambda_14_loss/GatherV2}} = GatherV2[Taxis=DT_INT32, Tindices=DT_INT64, Tparams=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](training_4/Adam/gradients/loss_7/lambda_14_loss/Mean_2_grad/Reshape, loss_7/lambda_14_loss/ArgMax, loss_7/lambda_14_loss/GatherV2/axis)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-101-17673d0b006b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m                     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mann_glob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     use_multiprocessing=False)\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'yolo'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'weights/model_weights.h5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2040\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2041\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2042\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2044\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1760\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1761\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1762\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1763\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2271\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2272\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2273\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2274\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: indices[0,12,0,0] = 1 is not in [0, 1)\n\t [[node loss_7/lambda_14_loss/GatherV2 (defined at /Users/zoe/robotics/brawl/yolo/loss.py:134)  = GatherV2[Taxis=DT_INT32, Tindices=DT_INT64, Tparams=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](training_4/Adam/gradients/loss_7/lambda_14_loss/Mean_2_grad/Reshape, loss_7/lambda_14_loss/ArgMax, loss_7/lambda_14_loss/GatherV2/axis)]]\n\nCaused by op 'loss_7/lambda_14_loss/GatherV2', defined at:\n  File \"/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/asyncio/base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/usr/local/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/usr/local/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n    self.run()\n  File \"/usr/local/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/usr/local/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/usr/local/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/usr/local/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n    return runner(coro)\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-101-17673d0b006b>\", line 5, in <module>\n    model.compile(loss=custom_loss, optimizer=optimizer) # , metrics=['accuracy']\n  File \"/usr/local/lib/python3.6/site-packages/keras/engine/training.py\", line 850, in compile\n    sample_weight, mask)\n  File \"/usr/local/lib/python3.6/site-packages/keras/engine/training.py\", line 450, in weighted\n    score_array = fn(y_true, y_pred)\n  File \"/Users/zoe/robotics/brawl/yolo/loss.py\", line 134, in custom_loss\n    class_mask = y_true[..., 4] * tf.gather(CLASS_WEIGHTS, true_box_class) * CLASS_SCALE\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 2675, in gather\n    return gen_array_ops.gather_v2(params, indices, axis, name=name)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 3332, in gather_v2\n    \"GatherV2\", params=params, indices=indices, axis=axis, name=name)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): indices[0,12,0,0] = 1 is not in [0, 1)\n\t [[node loss_7/lambda_14_loss/GatherV2 (defined at /Users/zoe/robotics/brawl/yolo/loss.py:134)  = GatherV2[Taxis=DT_INT32, Tindices=DT_INT64, Tparams=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](training_4/Adam/gradients/loss_7/lambda_14_loss/Mean_2_grad/Reshape, loss_7/lambda_14_loss/ArgMax, loss_7/lambda_14_loss/GatherV2/axis)]]\n"
     ]
    }
   ],
   "source": [
    "# model.get_layer('yolo').load_weights('model_weights.h5')\n",
    "\n",
    "# clipvalue=1, clipnorm=1 is for the exploding gradient problem\n",
    "optimizer = Adam(lr=0.5e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0, clipvalue=1., clipnorm=1.)\n",
    "model.compile(loss=custom_loss, optimizer=optimizer) # , metrics=['accuracy']\n",
    "\n",
    "ann_glob = glob('data/annotations/*')\n",
    "training_generator = BrawlDataGenerator(ann_glob)\n",
    "\n",
    "for i in range(1):\n",
    "    model.fit_generator(generator=training_generator,\n",
    "                    # validation_data=validation_generator,\n",
    "                    steps_per_epoch=len(ann_glob),\n",
    "                    epochs=15,\n",
    "                    use_multiprocessing=False)\n",
    "\n",
    "    model.get_layer('yolo').save_weights('weights/model_weights.h5', overwrite=True)\n",
    "    model.save('weights/full_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_layer('yolo').save_weights('model_weights.h5', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-28T18:59:32.876553Z",
     "start_time": "2018-12-28T18:59:29.065544Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-baef820cf5dc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_x\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mimg_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mimg_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mimg_input\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdummy_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTRUE_BOX_BUFFER\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_x' is not defined"
     ]
    }
   ],
   "source": [
    "img = test_x[5]\n",
    "img_input = img[..., ::-1]\n",
    "img_input = np.array([img_input])\n",
    "\n",
    "dummy_array = np.zeros((1, 1, 1, 1, TRUE_BOX_BUFFER, 4))\n",
    "\n",
    "test_prediction = model.predict([img_input, dummy_array])\n",
    "\n",
    "boxes = format_prediction(test_prediction[0], threshold=.13)\n",
    "# print(boxes)\n",
    "\n",
    "img = draw_boxes((img * 255).astype(np.uint8).copy() , boxes)\n",
    "img = img[..., ::-1]\n",
    "\n",
    "plt.imshow(img)\n",
    "# cv2.imwrite('cell.png',img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
