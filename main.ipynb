{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T16:43:59.199596Z",
     "start_time": "2018-12-20T16:43:59.191597Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, LeakyReLU, UpSampling2D, InputLayer, Concatenate, Input, merge, concatenate, Lambda, Reshape\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import plot_model\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing the config\n",
    "\n",
    "The network config is in `yolov3.cfg`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T04:19:00.023026Z",
     "start_time": "2018-12-20T04:19:00.010865Z"
    }
   },
   "outputs": [],
   "source": [
    "def parse_config(cfg_path, verbose=False):\n",
    "    file = open(cfg_path, 'r')\n",
    "    lines = file.readlines()\n",
    "        \n",
    "    # get rid of comments and blank lines and white space\n",
    "    lines = [x for x in lines if len(x) > 1]\n",
    "    lines = [x for x in lines if x[0] != '#']\n",
    "    lines = [x.rstrip().lstrip() for x in lines]\n",
    "\n",
    "    block = {}\n",
    "    blocks = []\n",
    "    \n",
    "    for line in lines:\n",
    "        if verbose: print('valuating line: %s' % line)\n",
    "        \n",
    "        if line[0] == '[': # new block start\n",
    "            if len(block) != 0: # if the block inst empty (has data) then reset it\n",
    "                blocks.append(block)\n",
    "                block = {}\n",
    "                \n",
    "            block['type'] = line[1:-1]\n",
    "        else:\n",
    "            key, value = line.split('=')\n",
    "            key, value = key.rstrip(), value.lstrip()\n",
    "            block[key] = value\n",
    "\n",
    "    return blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T04:19:00.035285Z",
     "start_time": "2018-12-20T04:19:00.028675Z"
    }
   },
   "outputs": [],
   "source": [
    "blocks = parse_config('yolov3.cfg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix shortcut issue\n",
    "this is a quick fix for the shortcut issue I was running into but I want to figure out why and how this works so I can create a better implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T16:34:41.655784Z",
     "start_time": "2018-12-20T16:34:41.651519Z"
    }
   },
   "outputs": [],
   "source": [
    "def space_to_depth_x2(x):\n",
    "    return tf.space_to_depth(x, block_size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The model\n",
    "\n",
    "(add specific info about the model)\n",
    "\n",
    "### Questions:\n",
    "1. Why is padding important in a convolutional layer\n",
    "2. What is `BatchNormalization` and why is it important\n",
    "3. What does `bilinear` mean?\n",
    "4. What is `B X C X H X W` and how is it difforent than other formats\n",
    "5. What is the difforence between route and shortcut and how are they implemented?\n",
    "    * see the degradation problem, and an [explaination here](https://www.quora.com/What-are-shortcut-connections-how-do-they-work-and-what-is-their-role-in-the-paper-Deep-Residual-Learning-for-Image-Recognition)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T17:00:48.691080Z",
     "start_time": "2018-12-20T17:00:37.124188Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convolutional, index: 0/107\n",
      "convolutional, index: 1/107\n",
      "convolutional, index: 2/107\n",
      "convolutional, index: 3/107\n",
      "shortcut, index: 4/107\n",
      "convolutional, index: 5/107\n",
      "convolutional, index: 6/107\n",
      "convolutional, index: 7/107\n",
      "shortcut, index: 8/107\n",
      "convolutional, index: 9/107\n",
      "convolutional, index: 10/107\n",
      "shortcut, index: 11/107\n",
      "convolutional, index: 12/107\n",
      "convolutional, index: 13/107\n",
      "convolutional, index: 14/107\n",
      "shortcut, index: 15/107\n",
      "convolutional, index: 16/107\n",
      "convolutional, index: 17/107\n",
      "shortcut, index: 18/107\n",
      "convolutional, index: 19/107\n",
      "convolutional, index: 20/107\n",
      "shortcut, index: 21/107\n",
      "convolutional, index: 22/107\n",
      "convolutional, index: 23/107\n",
      "shortcut, index: 24/107\n",
      "convolutional, index: 25/107\n",
      "convolutional, index: 26/107\n",
      "shortcut, index: 27/107\n",
      "convolutional, index: 28/107\n",
      "convolutional, index: 29/107\n",
      "shortcut, index: 30/107\n",
      "convolutional, index: 31/107\n",
      "convolutional, index: 32/107\n",
      "shortcut, index: 33/107\n",
      "convolutional, index: 34/107\n",
      "convolutional, index: 35/107\n",
      "shortcut, index: 36/107\n",
      "convolutional, index: 37/107\n",
      "convolutional, index: 38/107\n",
      "convolutional, index: 39/107\n",
      "shortcut, index: 40/107\n",
      "convolutional, index: 41/107\n",
      "convolutional, index: 42/107\n",
      "shortcut, index: 43/107\n",
      "convolutional, index: 44/107\n",
      "convolutional, index: 45/107\n",
      "shortcut, index: 46/107\n",
      "convolutional, index: 47/107\n",
      "convolutional, index: 48/107\n",
      "shortcut, index: 49/107\n",
      "convolutional, index: 50/107\n",
      "convolutional, index: 51/107\n",
      "shortcut, index: 52/107\n",
      "convolutional, index: 53/107\n",
      "convolutional, index: 54/107\n",
      "shortcut, index: 55/107\n",
      "convolutional, index: 56/107\n",
      "convolutional, index: 57/107\n",
      "shortcut, index: 58/107\n",
      "convolutional, index: 59/107\n",
      "convolutional, index: 60/107\n",
      "shortcut, index: 61/107\n",
      "convolutional, index: 62/107\n",
      "convolutional, index: 63/107\n",
      "convolutional, index: 64/107\n",
      "shortcut, index: 65/107\n",
      "convolutional, index: 66/107\n",
      "convolutional, index: 67/107\n",
      "shortcut, index: 68/107\n",
      "convolutional, index: 69/107\n",
      "convolutional, index: 70/107\n",
      "shortcut, index: 71/107\n",
      "convolutional, index: 72/107\n",
      "convolutional, index: 73/107\n",
      "shortcut, index: 74/107\n",
      "convolutional, index: 75/107\n",
      "convolutional, index: 76/107\n",
      "convolutional, index: 77/107\n",
      "convolutional, index: 78/107\n",
      "convolutional, index: 79/107\n",
      "convolutional, index: 80/107\n",
      "convolutional, index: 81/107\n",
      "yolo, index: 82/107\n",
      "route, index: 83/107\n",
      "start: -4, end: 0, all_modules: [Tensor(\"leaky_re_lu_316/LeakyRelu:0\", shape=(?, 24, 24, 512), dtype=float32)\n",
      "Tensor(\"leaky_re_lu_317/LeakyRelu:0\", shape=(?, 22, 22, 1024), dtype=float32)\n",
      "Tensor(\"leaky_re_lu_318/LeakyRelu:0\", shape=(?, 22, 22, 512), dtype=float32)\n",
      "Tensor(\"leaky_re_lu_319/LeakyRelu:0\", shape=(?, 20, 20, 1024), dtype=float32)\n",
      "Tensor(\"conv2d_327/BiasAdd:0\", shape=(?, 20, 20, 255), dtype=float32)]\n",
      "convolutional, index: 84/107\n",
      "upsample, index: 85/107\n",
      "route, index: 86/107\n",
      "start: -1, end: 0, all_modules: [Tensor(\"conv2d_327/BiasAdd:0\", shape=(?, 20, 20, 255), dtype=float32)\n",
      "Tensor(\"leaky_re_lu_320/LeakyRelu:0\", shape=(?, 20, 20, 256), dtype=float32)]\n",
      "convolutional, index: 87/107\n",
      "convolutional, index: 88/107\n",
      "convolutional, index: 89/107\n",
      "convolutional, index: 90/107\n",
      "convolutional, index: 91/107\n",
      "convolutional, index: 92/107\n",
      "convolutional, index: 93/107\n",
      "yolo, index: 94/107\n",
      "route, index: 95/107\n",
      "start: -4, end: 0, all_modules: [Tensor(\"leaky_re_lu_323/LeakyRelu:0\", shape=(?, 38, 38, 256), dtype=float32)\n",
      "Tensor(\"leaky_re_lu_324/LeakyRelu:0\", shape=(?, 36, 36, 512), dtype=float32)\n",
      "Tensor(\"leaky_re_lu_325/LeakyRelu:0\", shape=(?, 36, 36, 256), dtype=float32)\n",
      "Tensor(\"leaky_re_lu_326/LeakyRelu:0\", shape=(?, 34, 34, 512), dtype=float32)\n",
      "Tensor(\"conv2d_335/BiasAdd:0\", shape=(?, 34, 34, 255), dtype=float32)]\n",
      "convolutional, index: 96/107\n",
      "upsample, index: 97/107\n",
      "route, index: 98/107\n",
      "start: -1, end: 0, all_modules: [Tensor(\"conv2d_335/BiasAdd:0\", shape=(?, 34, 34, 255), dtype=float32)\n",
      "Tensor(\"leaky_re_lu_327/LeakyRelu:0\", shape=(?, 34, 34, 128), dtype=float32)]\n",
      "convolutional, index: 99/107\n",
      "convolutional, index: 100/107\n",
      "convolutional, index: 101/107\n",
      "convolutional, index: 102/107\n",
      "convolutional, index: 103/107\n",
      "convolutional, index: 104/107\n",
      "convolutional, index: 105/107\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'input_76:0' shape=(?, 608, 608, 3) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_262/LeakyRelu:0' shape=(?, 606, 606, 32) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_263/LeakyRelu:0' shape=(?, 302, 302, 64) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_264/LeakyRelu:0' shape=(?, 302, 302, 32) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_265/LeakyRelu:0' shape=(?, 300, 300, 64) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_262/LeakyRelu:0' shape=(?, 606, 606, 32) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_266/LeakyRelu:0' shape=(?, 302, 302, 128) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_267/LeakyRelu:0' shape=(?, 302, 302, 64) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_268/LeakyRelu:0' shape=(?, 300, 300, 128) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_262/LeakyRelu:0' shape=(?, 606, 606, 32) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_269/LeakyRelu:0' shape=(?, 606, 606, 64) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_270/LeakyRelu:0' shape=(?, 604, 604, 128) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_268/LeakyRelu:0' shape=(?, 300, 300, 128) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_271/LeakyRelu:0' shape=(?, 149, 149, 256) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_272/LeakyRelu:0' shape=(?, 149, 149, 128) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_273/LeakyRelu:0' shape=(?, 147, 147, 256) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_268/LeakyRelu:0' shape=(?, 300, 300, 128) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_274/LeakyRelu:0' shape=(?, 300, 300, 128) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_275/LeakyRelu:0' shape=(?, 298, 298, 256) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_273/LeakyRelu:0' shape=(?, 147, 147, 256) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_276/LeakyRelu:0' shape=(?, 147, 147, 128) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_277/LeakyRelu:0' shape=(?, 145, 145, 256) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_275/LeakyRelu:0' shape=(?, 298, 298, 256) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_278/LeakyRelu:0' shape=(?, 298, 298, 128) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_279/LeakyRelu:0' shape=(?, 296, 296, 256) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_277/LeakyRelu:0' shape=(?, 145, 145, 256) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_280/LeakyRelu:0' shape=(?, 145, 145, 128) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_281/LeakyRelu:0' shape=(?, 143, 143, 256) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_279/LeakyRelu:0' shape=(?, 296, 296, 256) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_282/LeakyRelu:0' shape=(?, 296, 296, 128) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_283/LeakyRelu:0' shape=(?, 294, 294, 256) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_281/LeakyRelu:0' shape=(?, 143, 143, 256) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_284/LeakyRelu:0' shape=(?, 143, 143, 128) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_285/LeakyRelu:0' shape=(?, 141, 141, 256) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_283/LeakyRelu:0' shape=(?, 294, 294, 256) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_286/LeakyRelu:0' shape=(?, 294, 294, 128) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_287/LeakyRelu:0' shape=(?, 292, 292, 256) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_285/LeakyRelu:0' shape=(?, 141, 141, 256) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_288/LeakyRelu:0' shape=(?, 70, 70, 512) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_289/LeakyRelu:0' shape=(?, 70, 70, 256) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_290/LeakyRelu:0' shape=(?, 68, 68, 512) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_285/LeakyRelu:0' shape=(?, 141, 141, 256) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_291/LeakyRelu:0' shape=(?, 141, 141, 256) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_292/LeakyRelu:0' shape=(?, 139, 139, 512) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_290/LeakyRelu:0' shape=(?, 68, 68, 512) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_293/LeakyRelu:0' shape=(?, 68, 68, 256) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_294/LeakyRelu:0' shape=(?, 66, 66, 512) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_292/LeakyRelu:0' shape=(?, 139, 139, 512) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_295/LeakyRelu:0' shape=(?, 139, 139, 256) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_296/LeakyRelu:0' shape=(?, 137, 137, 512) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_294/LeakyRelu:0' shape=(?, 66, 66, 512) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_297/LeakyRelu:0' shape=(?, 66, 66, 256) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_298/LeakyRelu:0' shape=(?, 64, 64, 512) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_296/LeakyRelu:0' shape=(?, 137, 137, 512) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_299/LeakyRelu:0' shape=(?, 137, 137, 256) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_300/LeakyRelu:0' shape=(?, 135, 135, 512) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_298/LeakyRelu:0' shape=(?, 64, 64, 512) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_301/LeakyRelu:0' shape=(?, 64, 64, 256) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_302/LeakyRelu:0' shape=(?, 62, 62, 512) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_300/LeakyRelu:0' shape=(?, 135, 135, 512) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_303/LeakyRelu:0' shape=(?, 135, 135, 256) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_304/LeakyRelu:0' shape=(?, 133, 133, 512) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_302/LeakyRelu:0' shape=(?, 62, 62, 512) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_305/LeakyRelu:0' shape=(?, 30, 30, 1024) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_306/LeakyRelu:0' shape=(?, 30, 30, 512) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_307/LeakyRelu:0' shape=(?, 28, 28, 1024) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_302/LeakyRelu:0' shape=(?, 62, 62, 512) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_308/LeakyRelu:0' shape=(?, 62, 62, 512) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_309/LeakyRelu:0' shape=(?, 60, 60, 1024) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_307/LeakyRelu:0' shape=(?, 28, 28, 1024) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_310/LeakyRelu:0' shape=(?, 28, 28, 512) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_311/LeakyRelu:0' shape=(?, 26, 26, 1024) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_309/LeakyRelu:0' shape=(?, 60, 60, 1024) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_312/LeakyRelu:0' shape=(?, 60, 60, 512) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_313/LeakyRelu:0' shape=(?, 58, 58, 1024) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_311/LeakyRelu:0' shape=(?, 26, 26, 1024) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_314/LeakyRelu:0' shape=(?, 26, 26, 512) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_315/LeakyRelu:0' shape=(?, 24, 24, 1024) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_316/LeakyRelu:0' shape=(?, 24, 24, 512) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_317/LeakyRelu:0' shape=(?, 22, 22, 1024) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_318/LeakyRelu:0' shape=(?, 22, 22, 512) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_319/LeakyRelu:0' shape=(?, 20, 20, 1024) dtype=float32>,\n",
       " <tf.Tensor 'conv2d_327/BiasAdd:0' shape=(?, 20, 20, 255) dtype=float32>,\n",
       " <tf.Tensor 'conv2d_327/BiasAdd:0' shape=(?, 20, 20, 255) dtype=float32>,\n",
       " <tf.Tensor 'conv2d_327/BiasAdd:0' shape=(?, 20, 20, 255) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_320/LeakyRelu:0' shape=(?, 20, 20, 256) dtype=float32>,\n",
       " <tf.Tensor 'up_sampling2d_5/ResizeBilinear:0' shape=(?, 40, 40, 256) dtype=float32>,\n",
       " <tf.Tensor 'up_sampling2d_5/ResizeBilinear:0' shape=(?, 40, 40, 256) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_321/LeakyRelu:0' shape=(?, 40, 40, 256) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_322/LeakyRelu:0' shape=(?, 38, 38, 512) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_323/LeakyRelu:0' shape=(?, 38, 38, 256) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_324/LeakyRelu:0' shape=(?, 36, 36, 512) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_325/LeakyRelu:0' shape=(?, 36, 36, 256) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_326/LeakyRelu:0' shape=(?, 34, 34, 512) dtype=float32>,\n",
       " <tf.Tensor 'conv2d_335/BiasAdd:0' shape=(?, 34, 34, 255) dtype=float32>,\n",
       " <tf.Tensor 'conv2d_335/BiasAdd:0' shape=(?, 34, 34, 255) dtype=float32>,\n",
       " <tf.Tensor 'conv2d_335/BiasAdd:0' shape=(?, 34, 34, 255) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_327/LeakyRelu:0' shape=(?, 34, 34, 128) dtype=float32>,\n",
       " <tf.Tensor 'up_sampling2d_6/ResizeBilinear:0' shape=(?, 68, 68, 128) dtype=float32>,\n",
       " <tf.Tensor 'up_sampling2d_6/ResizeBilinear:0' shape=(?, 68, 68, 128) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_328/LeakyRelu:0' shape=(?, 68, 68, 128) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_329/LeakyRelu:0' shape=(?, 66, 66, 256) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_330/LeakyRelu:0' shape=(?, 66, 66, 128) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_331/LeakyRelu:0' shape=(?, 64, 64, 256) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_332/LeakyRelu:0' shape=(?, 64, 64, 128) dtype=float32>,\n",
       " <tf.Tensor 'leaky_re_lu_333/LeakyRelu:0' shape=(?, 62, 62, 256) dtype=float32>,\n",
       " <tf.Tensor 'conv2d_343/BiasAdd:0' shape=(?, 62, 62, 255) dtype=float32>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_modle = Sequential()\n",
    "\n",
    "all_modules = [Input((608, 608, 3))] # add InputLayer for sequential\n",
    "module = all_modules[-1]\n",
    "\n",
    "# shortcut = None\n",
    "\n",
    "for index, block in enumerate(blocks[1:]): # block 0 specifies network info\n",
    "    print('%s, index: %i/%i' % (block['type'], index, len(blocks)))\n",
    "    \n",
    "    ### Conv(ish) layers\n",
    "    if block['type'] == 'convolutional':\n",
    "        # layer config\n",
    "        activation = block['activation']\n",
    "        \n",
    "        bais = False\n",
    "        try:\n",
    "            batch_normalize = int(block['batch_normalize'])\n",
    "        except:\n",
    "            batch_normalize = 0\n",
    "            bais = True\n",
    "            \n",
    "        filters = int(block['filters'])\n",
    "        padding = int(block['pad'])\n",
    "        kerel_size = int(block['size'])\n",
    "        strides = int(block['stride'])\n",
    "        \n",
    "# not working in keras\n",
    "#         if padding:\n",
    "#             pad = (kernel_size - 1) // 2\n",
    "#         else:\n",
    "#             pad = 0\n",
    "        \n",
    "        # create the conv layer\n",
    "        module = Conv2D(filters, kerel_size, strides=strides, use_bias=bais)(module)\n",
    "        \n",
    "        if batch_normalize:\n",
    "            module = BatchNormalization()(module)\n",
    "        \n",
    "        if activation == 'leaky':\n",
    "            module = LeakyReLU(0.1)(module)\n",
    "            \n",
    "    elif block['type'] == 'upsample':\n",
    "        stride = int(block['stride'])\n",
    "        module = UpSampling2D(size=(stride, stride), interpolation='bilinear')(module)\n",
    "\n",
    "    ### Routs and shortcuts    \n",
    "    elif block['type'] == 'route': # we need to connect these in the right way\n",
    "        layers = block['layers'].split(',')\n",
    "        start = int(layers[0])\n",
    "        \n",
    "        try:\n",
    "           end = int(blcok['layers'][1]) \n",
    "        except: # if there is no end\n",
    "            end = 0\n",
    "        \n",
    "        if start > 0:\n",
    "            start = start - index\n",
    "        if end > 0:\n",
    "            end = end - index\n",
    "        \n",
    "#         from IPython.core.debugger import Tracer; Tracer()()\n",
    "        \n",
    "        print('start: %d, end: %d, all_modules: [%s]' % (start, end, '\\n'.join(map(str, all_modules[index + start - 1: index + end]))))\n",
    "    \n",
    "        l1 = all_modules[index + start]\n",
    "        l2 = all_modules[index + end]\n",
    "        \n",
    "        if l1.shape[1] == l2.shape[1]: # hack to make sure tensors fit\n",
    "            module = concatenate([l1, l2])\n",
    "    \n",
    "    elif block['type'] == 'shortcut':\n",
    "        f = int(block['from'])\n",
    "        module = all_modules[index + f] # this is not great, but will be okay for now\n",
    "        \n",
    "#         from IPython.core.debugger import Tracer; Tracer()()\n",
    "#         shortcut = Lambda(space_to_depth_x2)(all_modules[index + f])\n",
    "#         module = concatenate([shortcut, module])\n",
    "\n",
    "    elif block['type'] == 'yolo': # this needs to also be connected to the network\n",
    "        mask = block['mask'].split(',')\n",
    "        mask = [int(x) for x in mask] # convert to ints\n",
    "        \n",
    "        anchors = block['anchors'].split(',')\n",
    "        anchors = [int(a) for a in anchors]\n",
    "        anchors = [(anchors[i], anchors[i + 1]) for i in range(0, len(anchors), 2)] # break anchors into pairs\n",
    "        anchors = [anchors[i] for i in mask]\n",
    "    \n",
    "    all_modules += [module]\n",
    "\n",
    "all_modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T17:00:57.794025Z",
     "start_time": "2018-12-20T17:00:57.411608Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_76 (InputLayer)        (None, 608, 608, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_269 (Conv2D)          (None, 606, 606, 32)      864       \n",
      "_________________________________________________________________\n",
      "batch_normalization_262 (Bat (None, 606, 606, 32)      128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_262 (LeakyReLU)  (None, 606, 606, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_273 (Conv2D)          (None, 302, 302, 128)     36864     \n",
      "_________________________________________________________________\n",
      "batch_normalization_266 (Bat (None, 302, 302, 128)     512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_266 (LeakyReLU)  (None, 302, 302, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_274 (Conv2D)          (None, 302, 302, 64)      8192      \n",
      "_________________________________________________________________\n",
      "batch_normalization_267 (Bat (None, 302, 302, 64)      256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_267 (LeakyReLU)  (None, 302, 302, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_275 (Conv2D)          (None, 300, 300, 128)     73728     \n",
      "_________________________________________________________________\n",
      "batch_normalization_268 (Bat (None, 300, 300, 128)     512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_268 (LeakyReLU)  (None, 300, 300, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_278 (Conv2D)          (None, 149, 149, 256)     294912    \n",
      "_________________________________________________________________\n",
      "batch_normalization_271 (Bat (None, 149, 149, 256)     1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_271 (LeakyReLU)  (None, 149, 149, 256)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_279 (Conv2D)          (None, 149, 149, 128)     32768     \n",
      "_________________________________________________________________\n",
      "batch_normalization_272 (Bat (None, 149, 149, 128)     512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_272 (LeakyReLU)  (None, 149, 149, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_280 (Conv2D)          (None, 147, 147, 256)     294912    \n",
      "_________________________________________________________________\n",
      "batch_normalization_273 (Bat (None, 147, 147, 256)     1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_273 (LeakyReLU)  (None, 147, 147, 256)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_283 (Conv2D)          (None, 147, 147, 128)     32768     \n",
      "_________________________________________________________________\n",
      "batch_normalization_276 (Bat (None, 147, 147, 128)     512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_276 (LeakyReLU)  (None, 147, 147, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_284 (Conv2D)          (None, 145, 145, 256)     294912    \n",
      "_________________________________________________________________\n",
      "batch_normalization_277 (Bat (None, 145, 145, 256)     1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_277 (LeakyReLU)  (None, 145, 145, 256)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_287 (Conv2D)          (None, 145, 145, 128)     32768     \n",
      "_________________________________________________________________\n",
      "batch_normalization_280 (Bat (None, 145, 145, 128)     512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_280 (LeakyReLU)  (None, 145, 145, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_288 (Conv2D)          (None, 143, 143, 256)     294912    \n",
      "_________________________________________________________________\n",
      "batch_normalization_281 (Bat (None, 143, 143, 256)     1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_281 (LeakyReLU)  (None, 143, 143, 256)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_291 (Conv2D)          (None, 143, 143, 128)     32768     \n",
      "_________________________________________________________________\n",
      "batch_normalization_284 (Bat (None, 143, 143, 128)     512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_284 (LeakyReLU)  (None, 143, 143, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_292 (Conv2D)          (None, 141, 141, 256)     294912    \n",
      "_________________________________________________________________\n",
      "batch_normalization_285 (Bat (None, 141, 141, 256)     1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_285 (LeakyReLU)  (None, 141, 141, 256)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_295 (Conv2D)          (None, 70, 70, 512)       1179648   \n",
      "_________________________________________________________________\n",
      "batch_normalization_288 (Bat (None, 70, 70, 512)       2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_288 (LeakyReLU)  (None, 70, 70, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_296 (Conv2D)          (None, 70, 70, 256)       131072    \n",
      "_________________________________________________________________\n",
      "batch_normalization_289 (Bat (None, 70, 70, 256)       1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_289 (LeakyReLU)  (None, 70, 70, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_297 (Conv2D)          (None, 68, 68, 512)       1179648   \n",
      "_________________________________________________________________\n",
      "batch_normalization_290 (Bat (None, 68, 68, 512)       2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_290 (LeakyReLU)  (None, 68, 68, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_300 (Conv2D)          (None, 68, 68, 256)       131072    \n",
      "_________________________________________________________________\n",
      "batch_normalization_293 (Bat (None, 68, 68, 256)       1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_293 (LeakyReLU)  (None, 68, 68, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_301 (Conv2D)          (None, 66, 66, 512)       1179648   \n",
      "_________________________________________________________________\n",
      "batch_normalization_294 (Bat (None, 66, 66, 512)       2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_294 (LeakyReLU)  (None, 66, 66, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_304 (Conv2D)          (None, 66, 66, 256)       131072    \n",
      "_________________________________________________________________\n",
      "batch_normalization_297 (Bat (None, 66, 66, 256)       1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_297 (LeakyReLU)  (None, 66, 66, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_305 (Conv2D)          (None, 64, 64, 512)       1179648   \n",
      "_________________________________________________________________\n",
      "batch_normalization_298 (Bat (None, 64, 64, 512)       2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_298 (LeakyReLU)  (None, 64, 64, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_308 (Conv2D)          (None, 64, 64, 256)       131072    \n",
      "_________________________________________________________________\n",
      "batch_normalization_301 (Bat (None, 64, 64, 256)       1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_301 (LeakyReLU)  (None, 64, 64, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_309 (Conv2D)          (None, 62, 62, 512)       1179648   \n",
      "_________________________________________________________________\n",
      "batch_normalization_302 (Bat (None, 62, 62, 512)       2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_302 (LeakyReLU)  (None, 62, 62, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_312 (Conv2D)          (None, 30, 30, 1024)      4718592   \n",
      "_________________________________________________________________\n",
      "batch_normalization_305 (Bat (None, 30, 30, 1024)      4096      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_305 (LeakyReLU)  (None, 30, 30, 1024)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_313 (Conv2D)          (None, 30, 30, 512)       524288    \n",
      "_________________________________________________________________\n",
      "batch_normalization_306 (Bat (None, 30, 30, 512)       2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_306 (LeakyReLU)  (None, 30, 30, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_314 (Conv2D)          (None, 28, 28, 1024)      4718592   \n",
      "_________________________________________________________________\n",
      "batch_normalization_307 (Bat (None, 28, 28, 1024)      4096      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_307 (LeakyReLU)  (None, 28, 28, 1024)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_317 (Conv2D)          (None, 28, 28, 512)       524288    \n",
      "_________________________________________________________________\n",
      "batch_normalization_310 (Bat (None, 28, 28, 512)       2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_310 (LeakyReLU)  (None, 28, 28, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_318 (Conv2D)          (None, 26, 26, 1024)      4718592   \n",
      "_________________________________________________________________\n",
      "batch_normalization_311 (Bat (None, 26, 26, 1024)      4096      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_311 (LeakyReLU)  (None, 26, 26, 1024)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_321 (Conv2D)          (None, 26, 26, 512)       524288    \n",
      "_________________________________________________________________\n",
      "batch_normalization_314 (Bat (None, 26, 26, 512)       2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_314 (LeakyReLU)  (None, 26, 26, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_322 (Conv2D)          (None, 24, 24, 1024)      4718592   \n",
      "_________________________________________________________________\n",
      "batch_normalization_315 (Bat (None, 24, 24, 1024)      4096      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_315 (LeakyReLU)  (None, 24, 24, 1024)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_323 (Conv2D)          (None, 24, 24, 512)       524288    \n",
      "_________________________________________________________________\n",
      "batch_normalization_316 (Bat (None, 24, 24, 512)       2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_316 (LeakyReLU)  (None, 24, 24, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_324 (Conv2D)          (None, 22, 22, 1024)      4718592   \n",
      "_________________________________________________________________\n",
      "batch_normalization_317 (Bat (None, 22, 22, 1024)      4096      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_317 (LeakyReLU)  (None, 22, 22, 1024)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_325 (Conv2D)          (None, 22, 22, 512)       524288    \n",
      "_________________________________________________________________\n",
      "batch_normalization_318 (Bat (None, 22, 22, 512)       2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_318 (LeakyReLU)  (None, 22, 22, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_326 (Conv2D)          (None, 20, 20, 1024)      4718592   \n",
      "_________________________________________________________________\n",
      "batch_normalization_319 (Bat (None, 20, 20, 1024)      4096      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_319 (LeakyReLU)  (None, 20, 20, 1024)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_327 (Conv2D)          (None, 20, 20, 255)       261375    \n",
      "_________________________________________________________________\n",
      "conv2d_328 (Conv2D)          (None, 20, 20, 256)       65280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_320 (Bat (None, 20, 20, 256)       1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_320 (LeakyReLU)  (None, 20, 20, 256)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2 (None, 40, 40, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_329 (Conv2D)          (None, 40, 40, 256)       65536     \n",
      "_________________________________________________________________\n",
      "batch_normalization_321 (Bat (None, 40, 40, 256)       1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_321 (LeakyReLU)  (None, 40, 40, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_330 (Conv2D)          (None, 38, 38, 512)       1179648   \n",
      "_________________________________________________________________\n",
      "batch_normalization_322 (Bat (None, 38, 38, 512)       2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_322 (LeakyReLU)  (None, 38, 38, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_331 (Conv2D)          (None, 38, 38, 256)       131072    \n",
      "_________________________________________________________________\n",
      "batch_normalization_323 (Bat (None, 38, 38, 256)       1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_323 (LeakyReLU)  (None, 38, 38, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_332 (Conv2D)          (None, 36, 36, 512)       1179648   \n",
      "_________________________________________________________________\n",
      "batch_normalization_324 (Bat (None, 36, 36, 512)       2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_324 (LeakyReLU)  (None, 36, 36, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_333 (Conv2D)          (None, 36, 36, 256)       131072    \n",
      "_________________________________________________________________\n",
      "batch_normalization_325 (Bat (None, 36, 36, 256)       1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_325 (LeakyReLU)  (None, 36, 36, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_334 (Conv2D)          (None, 34, 34, 512)       1179648   \n",
      "_________________________________________________________________\n",
      "batch_normalization_326 (Bat (None, 34, 34, 512)       2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_326 (LeakyReLU)  (None, 34, 34, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_335 (Conv2D)          (None, 34, 34, 255)       130815    \n",
      "_________________________________________________________________\n",
      "conv2d_336 (Conv2D)          (None, 34, 34, 128)       32640     \n",
      "_________________________________________________________________\n",
      "batch_normalization_327 (Bat (None, 34, 34, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_327 (LeakyReLU)  (None, 34, 34, 128)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_6 (UpSampling2 (None, 68, 68, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_337 (Conv2D)          (None, 68, 68, 128)       16384     \n",
      "_________________________________________________________________\n",
      "batch_normalization_328 (Bat (None, 68, 68, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_328 (LeakyReLU)  (None, 68, 68, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_338 (Conv2D)          (None, 66, 66, 256)       294912    \n",
      "_________________________________________________________________\n",
      "batch_normalization_329 (Bat (None, 66, 66, 256)       1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_329 (LeakyReLU)  (None, 66, 66, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_339 (Conv2D)          (None, 66, 66, 128)       32768     \n",
      "_________________________________________________________________\n",
      "batch_normalization_330 (Bat (None, 66, 66, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_330 (LeakyReLU)  (None, 66, 66, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_340 (Conv2D)          (None, 64, 64, 256)       294912    \n",
      "_________________________________________________________________\n",
      "batch_normalization_331 (Bat (None, 64, 64, 256)       1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_331 (LeakyReLU)  (None, 64, 64, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_341 (Conv2D)          (None, 64, 64, 128)       32768     \n",
      "_________________________________________________________________\n",
      "batch_normalization_332 (Bat (None, 64, 64, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_332 (LeakyReLU)  (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_342 (Conv2D)          (None, 62, 62, 256)       294912    \n",
      "_________________________________________________________________\n",
      "batch_normalization_333 (Bat (None, 62, 62, 256)       1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_333 (LeakyReLU)  (None, 62, 62, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_343 (Conv2D)          (None, 62, 62, 255)       65535     \n",
      "=================================================================\n",
      "Total params: 44,542,813\n",
      "Trainable params: 44,506,269\n",
      "Non-trainable params: 36,544\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "main_modle = Model(all_modules[0], module)\n",
    "main_modle.summary()\n",
    "plot_model(main_modle, to_file='model.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions\n",
    "Output and generating predictions\n",
    "\n",
    "### Output Tensor\n",
    "![image](https://cdn-images-1.medium.com/max/1600/1*cGfWw6lGmV1xUKRsd--JxQ.png)\n",
    "\n",
    "Each coordinate is represented like this:\n",
    "![image.png](https://blog.paperspace.com/content/images/2018/04/bbox_-2.png)\n",
    "the coordinates are the x, y in the matrix of anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
